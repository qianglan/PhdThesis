%*********************第三章******************
\chapter{3D卷积神经网络在异构平台上的高性能实现}
\label{3DWinograd}
\section{引言}
卷积神经网络在图像分类、目标跟踪等很多2D输入的处理任务已经得到了成功的应用。卷积神经网络能够很好地提取特征，所以卷积网络常用于图像分类，比如Alexnet\ref{}、VGG\ref{} 、googlenet\ref{}、resinet\ref{}等卷积神经网络被用来对2D图像进行分类，达到了很好的分类效果。图\ref{}为经典的Alexnet网络，其主要包含大量的卷积层，其中的计算也主要集中在卷积层。

正因为2D卷积网络得到了广泛的应用，所以研究人员开始转向3D卷积神经网络的研究，在\ref{}已经为我们展现了一个名为ObjectNet3D用于3D物体识别的数据库，通过这个数据库的训练，可以达到识别3D的各种姿势的目的，类似于这样的3D数据库还有ShapeNet\ref{}。针对这些3D数据库的3D卷积网络也开始陆续被设计出来，比如Voxnet\ref{}就是一个用于解决3D物体识别的3D卷积神经网络，文章\ref{}提出用3D卷积神经网络解决人类动作识别的方法，此外， 3D卷积神经网络可以处理视频分类的应用\ref{}。

但对于3D卷积神经网络的应用来说，如果仍然采用2D卷积神经网络的方法来处理，就会存在计算量大，存储消耗大的问题。有些方法只能解决其中的一个问题，比如基于FFT变换的方法在某些情况下可以有效降低计算量，但是以消耗存储为代价的。有一种卷积计算的快速算法，称为WMFA(Winograd Minimal Filtering Algorithm)，这种算法目前已经成功运用在2D卷积神经网络中，能够有效降低卷积中的计算量，并且不会增加额外的存储空间。因此，将2D WMFA应用到3D卷积神经网络中是非常值得研究的课题。本章内容主要是介绍3D WMFA算法在3D卷积网络上的应用，需要解决的问题包括，由2D WMFA算法的形式推倒出3D WMFA的形式；从理论上分析3D WMFA算法的复杂性，证明该算法在计算和存储开销上的优势；面向GPU异构平台，将3D WMFA算法高效地映射到GPU上。

本章内容安排如下：第二节介绍了关于卷积神经网络中加速的一些研究现状；第三节介绍快速卷积算法WMFA的3D形式，以及3D WMFA算法的复杂性分析；第四节将重点介绍3D WMFA算法的GPU实现，并且介绍了面向GPU的几种优化技术；第五节将对3D WMFA算法的性能进行评测，并与其它卷积方法的性能进行了对比；最后是对本章内容的总结，随着3D卷积网络应用的推广，对其进行加速变得尤为重要。

\section{相关研究}
对于卷积神经网络的加速，目前主要集中在对2D卷积神经网络的加速研究中，加速的方法主要包括网络结构的改进、算法的改进、深度学习框架中加速库的使用以及新的平台的使用。

Alexnet\ref{}是最早被提出的卷积神经网络，在图像分类应用中，与传统的机器学习分类方法\ref{}相比，分类精度得到大幅度提高，这也开启了对卷积神经网络研究的热潮。为了进一步提高效果，VGG\ref{}网络增加了卷积层的层数（最深多达19层卷积层），这样可以对待分类的图片提取更多的特征，提高分类的精度，虽然所有卷积核大小采用$3\times 3$的卷积核来控制计算量，但由于卷积层数多，计算量仍然很大。Network in Network(NIN)\ref{}是对卷积层的改进，卷积操作是一种线性变换，对特征为线性可分的输入分类效果会很好，而NIN就是解决输入为非线性可分的情况，NIN结构是在卷积层中间引入一个非线性变换操作。GoogleNet\ref{}的设计思路是通过增加网络的深度和宽度来提高分类的精度，但GoogleNet考虑到了计算量的问题，网络结构中引入了很多$1\times 1$的卷积核，该改进可以有效地防止计算量膨胀的问题。 squeezenet\ref{}网络结构在设计上也兼顾了计算量以及模型参数大小两方面，其主要优势就是在保证最后分类精度的情形下减少模型参数。

目前对于比较流行的深度学习框架，比如Caffe\ref{}、Tensorflow\ref{}、Theano\ref{}、Mxnet\ref{}等，它们都采用了专门优化的库实现其中的卷积计算。cblas是面向多核CPU的高效库，cuDNN\ref{}是面向Nvidia GPU的深度学习库。深度学习框架为深度学习开发者提供了一种非常简便的方式来开发深度学习应用，开发者只需要在配置文件中配置使用的平台，就能调用相应的库充分发挥这些底层平台的性能。

现有深度学习框架中调用的库中对卷积的实现大都是将卷积转化为矩阵乘的方法，矩阵分解的方法。。。。还有对卷积计算采用新的等价计算方法，比如FFT的方法\ref{}是将卷积转化为点乘，FFT方法针对卷积核比较大的卷积网络能够显著降低计算量，存在的唯一问题就是存储消耗过大。在卷积算法改进方面的研究还包括本章内容要介绍的应用到3D卷积网络的WMFA方法， Lavin\ref{}在GPU平台高效地实现了WMFA算法，取得了比cuDNN更好的性能。而在文章\ref{}中，作者面向的是FPGA平台，采用OpenCL实现了WMFA算法。无论是GPU平台还是FPGA平台，WMFA算法都表现了很好的并行性。

除了算法方面的改进，也有一些利用集群系统来提高卷积网络的性能。Adam等人开发的COTS HPC系统\ref{}是基于GPU服务器的集群系统，能够对大规模的神经网络进行训练。Google公司使用多年的分布式深度网络框架DistBelief\ref{}使用上千个CPU核心对几十亿的网络参数进行训练。Marthin等人\ref{}对训练的梯度下降法SGD\ref{}提出了一个高效的数据并行算法。H. Wang等人开发的MVAPICH2-GPU\ref{}针对集群中的InfiniBand连接，将CUDA集成在MPICH2中，从而解决了集群系统中的GPU间的通信问题，提高了MPI通信的效率。Mu Li等人\ref{}通过参数服务器的方法提高了在集群上训练的通信效率。

本章的工作主要是借鉴2D卷积网络中算法加速的相关研究，来加速3D卷积神经网络的计算过程。
\section{快速3D卷级算法}




\subsection{3D卷级神经网络定义}

\subsection{3D Winograd 算法}

\subsection{3D Winograd 算法的复杂性分析}


\section{3D Winograd 算法的实现与优化}

\subsection{3D Winograd 算法的实现}

\subsection{3D Winograd 算法的优化}


\section{实验评测与分析}
\subsection{实验设置}


\subsection{3D Winograd 算法各优化方法的性能}


\subsection{3D Winograd 算法各kernel执行时间分布}


\subsection{3D Winograd 算法与其它卷级算法性能比较}


\section{小结}

