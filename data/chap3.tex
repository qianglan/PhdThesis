%*********************第三章******************
\chapter{跟踪器中``目标候选''的作用分析和优化}
\label{chapijcv}

\section{引言}
在``目标候选''（原英语术语为``Detection Proposal''，这里采用意译）方法出现之前，
物体检测领域通常使用``滑动窗口（Sliding Window）''的方式来检测物体\upcite{slidingdetect1, slidingdetect2}。
滑动窗口指的是无视输入图像的实际内容，直接用一个窗口扫描整幅图像（在输入图像中不断滑动），
同时不断利用分类器判断窗口中的图像块是否包含目标物体。
由于物体可能是任意大小的，上述过程需要使用不同尺度和宽高比的窗口重复多次。
据统计，在常用的物体检测数据集\upcite{voc2007, coco}上，
一次单尺度的滑动窗口就会产生$10^4\sim 10^5$个候选窗口。
若引入不同的尺度和宽高比，窗口数目将高达$10^6\sim 10^7$\upcite{dpsurvey, dpsurvey2}。
因为整个物体检测过程所需时间等于一个窗口的分类时间乘以窗口数目，
巨大的候选窗口数量严重地限制了用于检测的分类器的复杂度，
使得物体分类领域的先进方法难以应用于物体检测任务。

为了减少滑动窗口所带来的巨大计算压力，``目标候选''方法应运而生。
所有目标候选方法均基于同一个假设，即任何包含物体的图像区域都具有一种共同的视觉特性，
该特性使得这些区域能够和背景区域区别开来。
因此，一定存在某种方法，能够以一幅图像为输入，然后输出一系列很可能包含着物体的候选区域。
这样的方法即是目标候选方法。
如果目标候选方法的输出能够足够准确地覆盖绝大部分物体，
且输出的候选区域数目远小于滑动窗口产生的（这在物体检测领域被称作``高召回率''），
那么物体检测过程将获得巨大的速度提升。
此外，使用更加复杂而准确的分类器也成为了可能，从而检测精度也将大幅提高。
经过多年的发展，目标候选方法已经具备了上述作用，在物体检测领域占有重要地位。
无论在经典的PASCAL数据集\upcite{voc2007}上，还是在庞大的ImageNet数据集\upcite{imagenet}上，
当前排名靠前的物体检测器均使用了目标候选方法\upcite{rcnn, detector1, detector2, detector3}。
实际的应用证明，除了上述作用以外，目标候选方法还能减少``错误肯定（False Positive）''对分类器的干扰，
从而进一步提升物体检测的准确性。

上一章中，通过将目标候选生成器EdgeBoxes不加修改地嵌入KCF跟踪器中，
获得了引人注目的尺度和宽高比适应力提升。
其中的整体方法是通用的，可用于将任何跟踪器和任何目标候选生成器进行结合。
该方法的本质在于，将目标候选生成器作为跟踪器运动模型的补充。
在理想情况下，即所有物体都被目标候选准确覆盖时，这种补充作用将会非常有效：
对于密集的运动模型，目标候选的灵活性将弥补运动模型固化的采样模式；
而对于随机的运动模型，目标候选对物体的感知力将弥补随机采样可能错过跟踪目标这一最大缺陷。
但是，上述的理想情况是难以满足的，目标候选生成器必然存在误差甚至错误，
而目前还尚未有任何文献讨论过目标候选的质量对于跟踪精度的影响。
此外，上一章仅对EdgeBoxes进行了参数调优，并没有对本质算法进行面向跟踪任务的优化，
因此KCFDP的性能还有着一定的提升空间。
本章将针对上述两个问题进行深入的研究。
一方面，通过将多个目标候选生成器逐一地与上一章的跟踪器进行结合，揭示了目标候选的质量和跟踪精度间有着密切的关系。
另一方面，通过为EdgeBoxes加入``背景抑制''这一优化步骤，以极低的时间开销提升了EdgeBoxes对于跟踪任务的适应性，
从而提高了整体跟踪性能。

本章的内容安排如下：
第2节介绍与本章相关的研究工作，主要是典型的目标候选生成器及它们在视觉跟踪中的应用；
第3节介绍目标候选生成器EdgeBoxes，并对其进行面向跟踪任务的优化；
第4节介绍如何将其它5个目标候选生成器和跟踪器相结合；
第5节进行实验，将分析目标候选质量对于跟踪精度的影响，并评测优化后的EdgeBoxes带来的性能提升；
第6节进行本章小结。



\section{相关研究}
``兴趣点检测（Interest Point Detection）\upcite{interestpoint1, interestpoint2}''和
``显著性检测（Saliency Detection）\upcite{saliency1, saliency2}''
在目标候选方法出现之前就是视觉领域重要的研究课题。
它们和目标候选方法有着相似的动机，但研究背景有所不同。
兴趣点检测和显著性检测主要依据仿生学原理，研究人的视觉系统规律，目的是从图像中找出能够吸引人类注意的突出区域和特别区域。
因此，它们常被用于物体分类、图像检索、图像对比等领域，以大幅减少计算开销。
而目标候选方法专注于物体检测，其本质在于研究物体所在的图像区域（而不是视觉上的显著区域）所具有的视觉特性，
即``物体性（Objectness）''。

目标候选方法在近几年发展迅速，形成了两种主要类型，
即``区域分组（Grouping）''类方法和``窗口评分（Window Scoring）''类方法\upcite{dpsurvey}。

SelectiveSearch\upcite{selectivesearch}是一种典型的区域分组方法，它首先利用边缘提取将图像划分为大量``超像素（Super Pixel）''，
然后使用贪心法将超像素进行合并，得到可能包含物体的各个区域。超像素合并的标准基于人工设计的特征和相似性度量，无需任何训练过程。
SelectiveSearch的应用在当前是最为广泛的，R-CNN\upcite{rcnn}和Fast R-CNN\upcite{fastrcnn}均基于它进行物体检测。
CPMC\upcite{cpmc}首先通过设置不同的``种子点（Seed）''和分割参数来进行多次图像分割（Graph Cut），
然后根据多种中层图像特征，将分割得到的图像分块进行筛选和排序，以得出可能包含物体的区域。
Geodesic\upcite{geodesic}会预先训练一个用于在图像中放置种子点的分类器。
基于该分类器放置的种子点，Geodesic将进行前背景分割，并利用分割结果计算``带符号的测地线距离变换（Signed Geodesic Distance Transformation，SGDT）''。
最后，超像素将根据不同的SGDT等级设置进行合并，得到目标候选区域。

与区域分组类的方法不同，窗口评分类方法通常产生密集的候选窗口，然后对候选窗口进行评分，以计算窗口内包含物体的可能性。
一些窗口评分方法甚至仍采用滑动窗口的方式来产生候选窗口，但是由于此时无需进行实际的物体分类，
其评分函数可以设计得非常高效，足以满足时效性要求。
Objectness\upcite{objectness}通常被认为是最早的目标候选生成器。
它首先进行显著性检测，并在显著区域附近提取大量候选窗口，
然后基于多种线索，利用贝叶斯框架对这些窗口的``物体性''进行评分。
Objectness的评分函数所采用的线索包括颜色、边界、位置、大小、以及非常有效的``超像素跨越''线索。
Bing\upcite{bing}的核心部分是一个以``规范化梯度（Norm of Gradients）''为输入特征的线性分类器。
经过在大型物体检测数据集上的训练，该分类器能够判断图像块内包含物体的概率。
通过对规范化梯度这一特征进行二进制近似，该线性分类器可变得极其高效，仅需几个原子操作即可完成。
因此即使Bing采用滑动窗口的方式提取候选窗口，其效率仍然是目前最高的。

上一章和本章所使用的EdgeBoxes\upcite{edgeboxes}也属于窗口评分类方法。
它首先进行边缘（Edge）提取，然后将边缘组合成边缘组（Edge Group），再考虑边缘组组成的物体边界（Contour）。
EdgeBoxes也采用了滑动窗口的方式，并且在给候选窗口评分时，认为完全包含在窗口内的边界数量就是``物体性''的体现。
上一章已经展示了EdgeBoxes在跟踪器中的巨大作用，
但同时也暴露出它的一些缺陷。
与物体检测任务不同，视觉物体跟踪仅关注被跟踪的目标物体，且对目标候选的准确度要求更高。
但是在跟踪场景下，EdgeBoxes很容易被非目标的物体边界，如属于背景、遮挡物、其它物体等的边界，所干扰，
从而生成不够准确甚至错误的目标候选。

就本文所知，最早将目标候选方法应用于物体跟踪的是上一章对应的论文\upcite{kcfdp}。
之后，目标候选在视觉跟踪过程中的作用得到了广泛的研究和开发\citep{proposalSelect, adobing, ebt, rpnt, moca}。
不同于上一章的KCFDP\upcite{kcfdp}，ADOBING\upcite{adobing}和\cite{proposalSelect}中的方法均没有
将目标候选作为运动模型的补充，而是将目标候选生成器所获取的``物体性''作为额外的跟踪依据，用于增强跟踪器的观察模型。
ADOBING\upcite{adobing}在初始化跟踪器时，
会利用自适应SVM\upcite{adaptivesvm}，对Bing的分类器进行面向被跟踪目标的修正。
修正后的Bing将作为观察模型的一部分，用于识别跟踪目标。
类似于ADOBING，\cite{proposalSelect}将EdgeBoxes的评分策略加入了跟踪器的辨别模型中，以更准确地区分目标物体和背景。
为了解决视觉跟踪中偶发的偏移问题，MOCA\upcite{moca}会周期性地根据``视觉显著性图''提取候选区域并进行辨别。
而在``视觉显著性图''中提取候选区域的过程也可以看作是一种目标候选生成器，
并且它在MOCA中的作用也是弥补原运动模型的不足。
EBT\upcite{ebt}和RPNT\upcite{rpnt}更进一步，它们直接使用修改后的目标候选生成器作为运动模型。
EBT在EdgeBoxes之上加入了一个针对跟踪目标的线性SVM分类器，以将目标候选重新排序，
使得生成的目标候选不仅包含``物体性''，还具有与跟踪目标的相似性。
RPNT使用在物体检测数据集上训练得到的区域候选网络（Region Proposal Network，RPN）\upcite{rpn}作为运动模型，
同时也在前一帧目标位置周围进行随机采样。


\section{跟踪器中目标候选生成器的优化}
通过加入上一章\ref{featureintegrasec}节中的特征整合和鲁邦更新优化，
KCFDP的跟踪器部分获得了显著的精度和鲁棒性提升。
但是作为尺度和宽高比适应力的来源，目标候选生成器在跟踪过程中仍然具有决定性的作用。
例如，如果生成的目标候选质量普遍较差，那么即使具有最高相关滤波响应值的目标候选，也无法用于描述目标物体的位置和大小。
此外，过多错误或者偏差的目标候选还会增加相关滤波器的误判概率，尤其是在背景较为杂乱时。
更严重的是，当错误的目标候选被相关滤波器误判时，该目标候选将被用于更新跟踪器的模型，造成模型的污染，
从而可能导致跟踪偏离目标。
因此，对目标候选生成器进行优化也是十分必要的。

目标候选生成器通常是``类别无关''的，即是说，它们的设计初衷就是生成能够覆盖图像中所有物体的目标候选，
包括那些背景物体和``不起眼''（低显著性）的物体。
但是，当目标候选生成器被用于物体跟踪时，我们期望生成的目标候选能够尽量集中于目标物体。
由于EdgeBoxes将物体边界作为唯一的``物体性''判断依据，它生成的目标候选很可能包含非目标物体边界，例如来自背景物体、
遮挡物体和其它背景纹理的边界。
这样的目标候选是不准确的，将会包括非目标的物体或者偏离目标中心。
为了缓解EdgeBoxes的这一缺陷，本节将对其进行优化。
具体地，本节将在滑动窗口和对窗口评分之前，添加一个额外的``背景抑制''步骤，
使得最终生成的目标候选不仅更加集中于目标物体，还能更准确地包围目标物体。

\subsection{目标候选生成器EdgeBoxes}
EdgeBoxes的思想可以概括为：边缘像素很可能属于物体的边界，而包围着完整物体边界的矩形框则很可能包含物体。
之所以强调包围``完整物体边界''，是因为如果一条物体边界跨越了边界框，那么该边界所属的物体将不处于该边界框内。
基于上述思想，EdgeBoxes将根据``被完全包围在边界框内的物体边界数量''来对候选窗口进行评分。

对于一幅输入图像，EdgeBoxes首先使用结构化边缘提取器\upcite{structurededge}为每一个像素计算出边缘响应值和边缘方向。
然后在垂直于各像素边缘方向的方向上进行非极大值抑制（Non-Maximal Suppression，NMS），
仅保留该方向上具有最大边缘响应的像素。
随后将响应值低于$0.1$的像素滤除，并把剩下的像素称作``边缘像素''。
这些边缘像素的响应值记为$m_p$，方向记为$\theta_p$。

边缘像素（Edge）将被组合成边缘组（Edge Group）。
组合的方法为：从各个像素出发进行贪心搜索，不断地将8个方向上邻接的、且边缘方向差别最小的边缘像素加入到边缘组中。
每一次加入新的边缘像素，都将其边缘方向差别累加，直到积累到大于某阈值（这里设置为$\pi/2$）就停止组合过程。
最后，过短的边缘组还将被融入邻近的较长边缘组中。

从直观角度来讲，如果两个边缘组邻接，且趋向相同，那么它们很可能属于同一条物体边界（Contour）；
反之，如果两者互相间隔，或者相邻但连接后形成大曲率曲线，那么它们很可能分属两条不同物体边界。
EdgeBoxes将两个边缘组属于同一条物体边界的可能性用``亲和度（Affinity）''来度量，其计算公式如下：
\begin{equation}
a(\textbf{s}_i,\textbf{s}_j)=|\cos(\theta_i-\theta_{ij})\cos(\theta_j-\theta_{ij})|^\gamma, \label{edge_affinity}
\end{equation}
其中$a(\textbf{s}_i,\textbf{s}_j)$代表边缘组$\textbf{s}_i$和$\textbf{s}_j$间的亲和度，
$\theta_{i}$和$\theta_{j}$分别是两个边缘组的平均边缘方向。
记两个边缘组的平均位置坐标为$x_i$和$x_j$，则上式中的$\theta_{ij}$就是从$x_i$到$x_j$所形成的直线方向。
显然，如果两个边缘组的平均方向（$\theta_{i}$和$\theta_{j}$）与它们相连后的趋向（$\theta_{ij}$）相近，
那么它们间将具有较大亲和度。
上式的$\gamma$用于调整亲和度对于方向的敏感度，这里设置为$2$。
此外，如果两个边缘组间隔$2$个像素以上，则亲和度设置为$0$。
EdgeBoxes将计算出任意两对边缘组间的亲和度，以用于窗口评分。
由于大部分的边缘组是互相间隔的，亲和度计算的实际开销并不大。

完成上述的边缘组提取和亲和度计算后，将进入滑动窗口和对各个窗口评分的过程。
在进行滑动窗口之前，为了提高计算效率，
EdgeBoxes会预先为图像中的每一个边缘组$\textbf{s}_i$计算出组内像素的总响应值，记为$m_i$。
然后为每个边缘组随机提取一个像素$\overline{x}_i$，并记录下来，以快速判断各边缘组是否在某窗口内。
滑动窗口的过程和控制参数已经在\ref{param_setup}节中介绍过了，这里不再赘述，仅详细介绍对一个窗口$b$的评分过程。
为了能够度量``被完全包围在边界框内的物体边界数量''，EdgeBoxes将为每个边缘组$\textbf{s}_i$计算一个权值$w_b(\textbf{s}_i)\in [0,1]$。
它代表着$\textbf{s}_i$所在的物体边界被完全包含在窗口内的概率。
对于所有跨过窗口$b$的边界的边缘组，记它们组成的集合为$S_b$。
显然如果$\textbf{s}_i\in S_b$，则应有$w_b(\textbf{s}_i)=0$。
类似的，对于任何$\textbf{s}_i$，如果对应的$\overline{x}_i\notin b$，则$w_b(\textbf{s}_i)=0$，因为此时$\textbf{s}_i$只有两种可能：
全部处于窗口$b$之外，或者$\textbf{s}_i\in S_b$。
对于余下的边缘组，即$\overline{x}_i\in b$且$\textbf{s}_i\notin S_b$，按下式计算其$w_b(\textbf{s}_i)$：
\begin{equation}
w_b(\textbf{s}_i)=1-\max_\textbf{T}{\prod_{j=1}^{|\textbf{T}|-1}a(\textbf{t}_j,\textbf{t}_{j+1})}. \label{wbsi}
\end{equation}
上式中，$\textbf{T}$代表一系列边缘组（或者称为一条``路径''），它从某一边缘组$\textbf{t}_1\in S_b$出发，
至$\textbf{t}_{|\textbf{T}|}=\textbf{s}_i$结束，长度为$|\textbf{T}|$。
如果不存在这样的路径，则$w_b(\textbf{s}_i)=1$。
也即是说，上式将找出一条从$\textbf{s}_i$到窗口$b$边界的具有最大亲和度的路径，
然后根据这条路径是一条物体边界的概率（即路径上边缘组亲和度的乘积），对$w_b(\textbf{s}_i)$进行惩罚。
由于大部分边缘组间的亲和度为$0$，因此上述过程也较为高效。

获得$w_b$后，即可为窗口$b$进行评分，评分函数为：
\begin{equation}
	h_b = \frac{\sum_{i}w_b(\textbf{s}_i)m_i}{2(b_w+b_h)^\kappa} - \frac{\sum_{p\in b^{in}}m_p}{2(b_w+b_h)^\kappa}. \label{edgeboxes-full}
\end{equation}
上式和上一节的公式\ref{edgeboxes}虽然形式上不同，但实质是相同的。
这里$i$不再代表像素，而是边缘组的编号。$m_i$为边缘组内像素的总响应值，而$m_p$为像素$p$的边缘响应值。
由于边缘并没有宽度，所以用于惩罚较大窗口的分母是基于周长而不是面积的。
目标候选生成器Objectness\upcite{objectness}已经证明，窗口中心部分的边界信息对于``物体性''几乎没有贡献，
因此评分函数最终将减去位于$b^{in}$内的全部像素的边缘响应值。

\subsection{使用背景抑制优化EdgeBoxes}
\label{backsuppresssec}
在KCFDP中，如图\ref{process}(b)所示，输入EdgeBoxes的图像块（尺度和宽高比检测窗口）
的中心位于KCF得出的``初步目标位置''，其尺度大于上一帧的目标大小。
鉴于优化后的KCF具有足够的准确性，并且目标物体的尺度变化通常慢于位置变化，
此时可以做出一个合理的假设：当前帧中的目标物体被完全包含在EdgeBoxes的输入图像块中。
显然，在这种情况下，若一条物体边界跨越了输入图像块的边界，那么该物体边界必然不属于目标物体。
这样一来，本节得到了一种可靠地判断非目标物体边界的方法。

如本节开头所述，跟踪任务中EdgeBoxes极易被非目标物体边界所干扰。
如果能够将非目标物体边界消除，那么EdgeBoxes生成的目标候选将集中于目标物体，且更加准确。
但是，上述对非目标物体边界的判断方法并不完美（物体大小发生剧烈变化时可能超出图像块的范围），
并且EdgeBoxes对边缘组是否属于同一边界的判断标准也存在误差（目标物体边缘组和非目标物体边缘组间也可能有较高亲和度），
因此本节仅对判断出的非目标物体边界进行``抑制''，称为``背景抑制（Background Suppression）''，
而不是彻底地去除非目标物体边界。

对于EdgeBoxes的输入图像块$\mathbf{z}$，在边缘组提取和亲和度计算之后，在滑动窗口和窗口评分之前，
本节将根据$\mathbf{z}$中各个边缘组属于非目标物体边界的可能性，对它们的边缘响应值进行惩罚，以达到背景抑制的目的。
对于$\mathbf{z}$内的每个边缘组$\textbf{s}$，首先计算它的``抑制因子（Suppression Factor）''：
\begin{equation}
\mu_\mathbf{z}(\textbf{s})=\frac{1}{4}\max_{\textbf{T}'}{\prod_{j=1}^{|\textbf{T}'|-1}a(\textbf{t}'_j,\textbf{t}'_{j+1})}. \label{sup_factor}
\end{equation}
该式和公式\ref{wbsi}十分相似，不同的是，$\textbf{T}'$代表的是从$\textbf{s}$出发到达输入图像$\mathbf{z}$边界的路径，
而不是到达某边界框边界的路径。
$\textbf{T}'$上边缘组间的亲和度乘积，代表着$\textbf{T}'$是一条物体边界的概率。
又由于$\textbf{T}'$跨越了输入图像$\mathbf{z}$的边界，很可能是一条非目标物体边界，
因此抑制因子$\mu_\mathbf{z}(\textbf{s})$与$\textbf{s}$属于非目标物体边界的概率是正相关的。
为了快速计算所有$\textbf{s}$的抑制因子$\mu_\mathbf{z}(\textbf{s})$，
本节将采用一个近似的贪心算法：
找出所有位于$\mathbf{z}$的边界上的边缘组，记它们的集合为$S_{\mathbf{z}}$。
然后对于每一个$\textbf{s}_j\in S_{\mathbf{z}}$，逆向寻找与其有最大亲和度的边缘组$\textbf{s}_{j+1}$，
并计算$\textbf{s}_{j+1}$的抑制因子。
然后从$\textbf{s}_{j+1}$出发，继续搜索与$\textbf{s}_{j+1}$有最大亲和度的边缘组，直到抑制因子小于$0.05$。
计算出$\mathbf{z}$内每个边缘组$\textbf{s}_i$的抑制因子后，
将根据抑制因子对边缘组的总边缘响应值$m_i$进行抑制：
\begin{equation}
m_i=m_i\times(1-\mu_\mathbf{z}(\textbf{s}_i)). \label{sup_pixel}
\end{equation}
之后将进入滑动窗口和对各窗口的评分，
抑制后的边缘组总响应值将被用于EdgeBoxes的评分函数（公式\ref{edgeboxes-full}）中。
作为背景抑制的结果，包围非目标物体边界的候选窗口的评分将会降低，
而仅包围目标物体边界的候选窗口的评分将相对提升，
从而EdgeBoxes输出的目标候选将更加集中于被跟踪的目标物体。

因为背景抑制中所利用的亲和度$a(\cdot, \cdot)$将被后续的窗口评分重用，
并且计算抑制因子时使用了近似的贪心算法，
所以背景抑制的实际计算开销会小于对一个候选窗口（该窗口包围了整个输入图像块）的评分。
考虑到滑动窗口将会产生大量候选窗口，背景抑制的计算开销是极小的。

此外，若被跟踪的目标物体很小，或者图像分辨率很低，那么输入EdgeBoxes的图像块也会很小。
在这样的图像块中提取的边缘将较为稀疏，且误差较大，导致目标物体边界和非目标物体边界容易发生混淆，
因此本节将仅对大于$64\times64$的输入图像块进行背景抑制。
通过实验验证（\ref{parameter-sensitivity}节），上述的图像大小阈值可以一定程度地提高跟踪准确性。

背景抑制的可视化效果如图\ref{punish}所示。
在每一个子图中，从左到右分别是原输入图像块、背景抑制前的边缘响应图和抑制后的边缘响应图。
边缘响应图中的颜色越深，代表像素具有越高的边缘响应值。
矩形边界框标识的是被跟踪的目标物体，椭圆形框标识的是被明显抑制的非目标物体边界。
3个子图分别来自于视频序列\textit{Tiger1}、\textit{Singer2}和\textit{David3}\upcite{50seqs}。
从边缘响应值的降低可以看出，图中的非目标物体边界被有效地抑制了。
在EdgeBoxes提取目标候选时，这些被抑制边界的作用将大大降低，从而生成的目标候选将偏离这些边界，转而集中到目标物体。

\begin{figure}
	\centering
	\includegraphics[width=10cm]{Fig2.jpg}
	\caption{背景抑制的可视化效果}
	\label{punish}
\end{figure}



\section{跟踪器中目标候选生成器的适配}
\label{generatoradaptsec}
本节的目的有两个方面。
一方面，本节通过将不同的目标候选生成器向跟踪任务进行适配，并利用上一章的方法嵌入跟踪器中，
将揭示目标候选质量和跟踪精度间的关系。
另一方面，通过对比嵌入不同目标候选生成器后的跟踪器精度，将证明本章对EdgeBoxes的优化是非常有效的。

在进行本节的工作前，目标候选对于跟踪器的作用是不明朗的。
如果目标候选在物体跟踪中没有作用，
那么不使用目标候选生成器，仅仅在目标初步位置附近进行随机采样，也能获得近似的跟踪精度提升。
目标候选生成器Bing\upcite{bing}就是一个典型的例子。
有文献指出，Bing的分类器并没有实际作用\upcite{crackingbing}。
如果无视图像实际内容，单纯按照一定模式采样目标候选，也可以生成同等质量的目标候选。
本节的工作和对应的实验结果将证明，目标候选对于跟踪精度的影响很大，
且目标候选的质量和跟踪器的准确性是正相关的。

在对目标候选生成器进行适配之前，本节将首先介绍目标候选的质量度量方法。
目标候选的初衷是为物体检测提供初步的候选区域，以加速对所有候选区域的分类过程。
因此，评价一个目标候选生成器提取的目标候选质量的最可靠标准就是，将其嵌入物体检测器后获得的物体检测精度（通常用召回率来度量）。
但是，由于物体检测器本身具有不同的质量和特点，适用的目标候选生成器也不尽相同，因此上述标准难以实际应用。
\cite{dpsurvey}率先提出了一种新的目标候选质量度量\pozhehao 平均召回率（Average Recall）图。
要得到平均召回率图无需真正地进行物体检测，其计算方式如下。
在物体检测测试集中，将每幅图像输入目标候选生成器。
然后将测试集的正确结果（准确包围各个物体的边界框）和所有目标候选进行对比，
如果某物体边界框和任意一个目标候选边界框的重叠率（IoU）超过一个阈值（记为$IoU\_threshold$），
则认为目标候选成功覆盖了该物体。
将被覆盖的物体数目除以所有物体数目，即得到了召回率（Recall）。
显然，生成的目标候选数量不同，或者$IoU\_threshold$不同，都将得到不同的召回率。
通过控制目标候选生成器的参数，令其生成一定数量的目标候选，
然后将$IoU\_threshold$分别设置为$0.5\sim 1$（以$0.1$为步长），计算其召回率。
对不同$IoU\_threshold$下的召回率取平均值，即可得到平均召回率。
最后，令目标候选生成器生成不同数量的目标候选，并将目标候选数量（沿横坐标）和对应的平均召回率（沿纵坐标）绘制成图表，
即得到了平均召回率图。
通过平均召回率图，将能够明确地判断出不同目标候选生成器生成的目标候选质量。

\cite{dpsurvey}通过在三大物体检测数据集（PASCAL VOC 2007、ImageNet、MS COCO）上计算平均召回率图，
将常用的目标候选生成器的质量和速度总结出来，如表\ref{methods-comparison}所示。
表\ref{methods-comparison}中列出了不同目标候选生成器所属的类别、在一帧图像上生成目标候选所需的平均时间、
以及生成的目标候选质量等级。
质量等级按照从低到高的顺序，逐级标记为``$\cdot$''、``$\star$''、``$\star\star$''和``$\star\star\star$''。

\begin{table}[htb]
\begin{centering}
\caption{常用目标候选生成器的质量和速度对比\upcite{dpsurvey}}
\label{methods-comparison}
\begin{tabular}{ccccccccccc}
\hline
{\small{}名称} &  & {\small{}类别} & {\small{}平均时间开销（秒）} & {\small{}目标候选质量}\tabularnewline
% &  &  & {\small{}（单位：秒）} & \tabularnewline
\hline 
\texttt{\small{}Bing }{\small{}\upcite{bing}} &  & {\small{}窗口评分} & 0.2 & $\cdot$\tabularnewline
\texttt{\small{}CPMC }{\small{}\upcite{cpmc}} &  & {\small{}区域分组} & 250 & $\star$\tabularnewline
\texttt{\small{}EdgeBoxes }{\small{}\upcite{edgeboxes}} &  & {\small{}窗口评分} & 0.3 & $\star\star\star$\tabularnewline
\texttt{\small{}Endres }{\small{}\upcite{endres}} &  & {\small{}区域分组} & 100 & $\star\star$\tabularnewline
\texttt{\small{}Geodesic }{\small{}\upcite{geodesic}} &  & {\small{}区域分组} &  1 & $\star\star$\tabularnewline
\texttt{\small{}MCG }{\small{}\upcite{mcg}} &  & {\small{}区域分组} & 30 & $\star\star\star$\tabularnewline
\texttt{\small{}Objectness }{\small{}\upcite{objectness}} &  & {\small{}窗口评分} & 3 & $\cdot$\tabularnewline
\texttt{\small{}Rahtu }{\small{}\upcite{rahtu}} &  & {\small{}窗口评分} &  3 & $\star$\tabularnewline
\texttt{\small{}RandomizedPrim's }{\small{}\upcite{randomizedprim}} &  & {\small{}区域分组} & 1 & $\star\star$\tabularnewline
\texttt{\small{}Rantalankila }{\small{}\upcite{rantalankila}} &  & {\small{}区域分组} & 10 & $\star\star$\tabularnewline
\texttt{\small{}Rigor }{\small{}\upcite{rigor}} &  & {\small{}区域分组} & 10 & $\star\star$\tabularnewline
\texttt{\small{}SelectiveSearch }{\small{}\upcite{selectivesearch}} &  & {\small{}区域分组} & 10 & $\star\star\star$\tabularnewline
\hline 
\texttt{\small{}Baseline\_Gaussian} &  & {\small{}基准}  &  0 & $\star$\tabularnewline
\texttt{\small{}Baseline\_Uniform} &  & {\small{}基准}  &  0 & $\cdot$\tabularnewline
\end{tabular}
\par\end{centering}
\end{table}

通过分析表\ref{methods-comparison}，本节将4个目标候选生成器\pozhehao EdgeBoxes、Geodesic、Objectness和Bing，
以及两个基准方法\pozhehao 高斯随机采样（Gaussian）和均匀随机采样（Uniform），分别嵌入跟踪器中。
嵌入不同目标候选生成器的方法和上一章\ref{wholeprocesssec}节一样，
即将算法\ref{algorithm}第4步的EdgeBoxes替换为其它生成器。
跟踪器部分，包括图像特征整合、鲁棒模型更新以及目标候选过滤等，均不作任何修改。
此外，本节还将未嵌入任何目标候选生成器的跟踪器也考虑进来。
最后，再将本章加入背景抑制优化后的EdgeBoxes也嵌入跟踪器中，总共得到8个跟踪器。
参数的设置均保持与上一章\ref{param_setup}节一致。

之所以选用上述目标候选生成器，最重要的原因在于它们生成目标候选的时间开销较少。
一些常用的目标候选生成器，如SelectiveSearch、MCG和CPMC，
虽然也能够生成较高质量的目标候选，但是时间开销太大，无法满足跟踪任务对时效性的需求，因此本节不作考虑。
另一个原因在于目标候选的质量。
本节希望分析出不同候选质量对于跟踪精度的影响，因此选择的生成器覆盖了不同的目标候选质量等级。

在将各个目标候选生成器嵌入跟踪器之前，需要对它们进行适配。
这里的适配指的是对生成器的参数进行调整，或者是对可选模块进行替换，
但是不对其核心算法进行任何修改。
进行适配的目的有两个，一是通过分析参数的实际作用来适当地调优参数，以在保证足够跟踪速度的同时，
尽量提高跟踪精度；
二是通过调整对生成候选数目有直接或者间接影响的参数，让各个生成器生成的目标候选数量相近（120个左右），
以保证跟踪精度对比的公平性。
针对各个目标候选生成器的具体适配工作介绍如下：
\begin{compactitem}
\item \textbf{EdgeBoxes}
\end{compactitem}

参数的设置参见上一章\ref{param_setup}节。
嵌入了适配后的EdgeBoxes的跟踪器实际上就是上一章得到的KCFDP。
\begin{compactitem}
\item \textbf{Geodesic}
\end{compactitem}

本节将基本沿用\cite{dpsurvey}中建议的参数设置，仅做一些细微改动。
Geodesic的第一步是利用多尺度的结构化边缘提取器\upcite{structurededge}来提取边缘，并将图像分割为超像素。
考虑到多尺度结构化边缘提取器的时间开销过大，并且跟踪任务中输入Geodesic的图像块的尺度通常较小，无需多尺度边缘提取，
因此这里将其替换为单尺度的结构化边缘提取器。
在进行前背景分割时，本节仅放置20个种子点来构成前景，原因在于目标物体通常占据了输入图像块的大部分，20个种子点足够命中目标物体。
根据\ref{backsuppresssec}节开头的分析，目标物体通常被完全包含在输入图像块中，因此本节将输入图像块的边界和一个空集合作为背景。
相比完整图像，输入图像块中的物体数量要少得多，故用于合并超像素的``SDGT等级集合''的数量被设置为5个。
\begin{compactitem}
\item \textbf{Objectness}
\end{compactitem}

Objectness为了计算``物体性''，在评分函数中使用了多种线索。
由于其算法本身开销较大，本节仅采用其中最有代表性的两种线索，即多尺度显著性（Multi-Scale Saliency，MS）和
跨越的超像素数目（Superpixels Straddling，SS）。
虽然仅使用了两种线索，但是根据\cite{objectness}中的实验，此时Objectness已经可以达到与使用全部线索时相当的性能。
考虑到跟踪任务中输入的图像块要简单得多，本节将Objectness的初步采样窗口数目降低到$1200$个。配合显著性检测，
该数目足以覆盖目标物体。
基于同样原因，计算多尺度显著性线索时使用的尺度集合缩小为$\{16, 32\}$。
在最后的非极大值抑制步骤中，本节将IoU阈值从$0.5$提升到$0.7$，以提高覆盖目标物体的目标候选的准确度。
该步骤中的最大输出窗口数也更改为$120$，以确保它生成的目标候选数量和其它目标候选生成器相近。
\begin{compactitem}
\item \textbf{Bing}
\end{compactitem}

Bing主要基于一个训练出来的线性分类器，因此可供调节的参数很少。
本节保留\cite{bing}中推荐的参数设置，并采用其Matlab封装\upcite{bingImpl}后的版本。
线性分类器的模型直接采用\cite{bingImpl}中在PASCAL VOC 2007数据集上训练得到的结果。
此外，本节将非极大值抑制大小（Non-Maximal Suppression Size，NSS）减小为$1$，以产生更为密集的目标候选，
从而提高覆盖目标物体的目标候选的准确度。
\begin{compactitem}
\item \textbf{Baseline\_Uniform}
\end{compactitem}

该目标候选生成器即是表\ref{methods-comparison}中的Baseline\_Uniform。
它在\cite{dpsurvey}中作为一个测试基准，用于和其它目标候选生成器进行对比。
Baseline\_Uniform认为，图像中物体的相对中心位置、面积的平方根、宽高比的对数都是均匀分布的，
并根据PASCAL VOC 2007的正确结果统计出它们的范围。
在生成目标候选时，Baseline\_Uniform无视图像实际内容，
仅按照统计结果对相对中心位置、面积的平方根、宽高比的对数进行随机均匀采样，
并输出对应的边界框作为目标候选。
本节将采样$120$次，即生成$120$个目标候选。
\begin{compactitem}
\item \textbf{Baseline\_Gaussian}
\end{compactitem}

该目标候选生成器即是表\ref{methods-comparison}中的Baseline\_Gaussian。
类似Baseline\_Uniform，它也是\cite{dpsurvey}中的一个测试基准。
不同的是，它认为图像中物体的相对中心位置、面积的平方根、宽高比的对数是服从一个多元高斯分布（Multi-Variate Gaussian）的，
并根据PASCAL VOC 2007的正确结果估计出了该多元高斯分布的参数。
在生成目标候选时，Baseline\_Gaussian同样无视图像实际内容，
仅按照该多元高斯分布对相对中心位置、面积的平方根、宽高比的对数进行随机采样，
并输出对应的边界框作为目标候选。
同理，将采样$120$次以生成$120$个目标候选。

在经过上述的适配之后，6个目标候选生成器将被分别嵌入跟踪器中，并与嵌入了本章优化后的EdgeBoxes的跟踪器，
以及未嵌入目标候选生成器的跟踪器进行性能对比。
对比的结果和相关分析将在\ref{dpeffectsec}节中进行介绍。




\section{实验评测与分析}
\subsection{实验设置}
为了与上一章的KCFDP区分开来，这里把沿用了上一章方法，并嵌入了本章优化后的EdgeBoxes的跟踪器
命名为``KCFDPT（Kernelized Correlation Filter with Detection Proposals for Tracking）''。
KCFDPT的参数设置保持和上一章\ref{param_setup}节一样，但是为了测试这些参数的作用，
以及证明这些参数设置的有效性，本节将进行额外的参数敏感性分析（Parameter Sensitivity Analysis）。
由于EdgeBoxes采用C++进行实现，因此本章中EdgeBoxes的背景抑制优化也使用C++实现。
其余部分的实现均保持不变，直接采用上一章的程序。
硬件和软件环境也保持和上一章相同。

本节的实验评测主要分为两个部分：一部分是将嵌入了不同目标候选生成器的跟踪器进行对比，
以分析目标候选在跟踪器中的作用，并同时证明本章对EdgeBoxes的背景抑制优化的有效性；
另一部分是将KCFDPT和不同的跟踪器进行对比，以体现优化后的EdgeBoxes对于跟踪任务的较高适应性。

在第一部分实验中，主要测试集仍然采用上一章的OTB以及它的两个子集，即``尺度变化''子集和``宽高比变化''子集。
对照组为\ref{generatoradaptsec}节中嵌入了不同目标候选生成器的跟踪器。
评价标准仍然沿用上一章\ref{evalcriteriasec}节的准确率图和成功率图。
在第二部分实验中，对照组与上一章\ref{datasetcomponetsec}节相同，由34个跟踪器组成。
由于KCFDPT的准确性优于KCFDP，它在OTB测试集及其两个子集上的准确率图和成功率图与上一章相似，
因此这里不再基于统计图进行对比，而是将OTB测试集进一步细分，得出具有不同尺度变化速度和程度、
以及具有不同宽高比变化速度和程度的子集。
在这些子集上，本节将进行数值化的距离精度和重叠精度对比。
此外，为了测试KCFDPT的通用性，本节还将在VOT 2014测试集上进行额外的实验。
由于VOT 2014提供了自己的评价标准，故将在对应章节进行专门介绍。

\subsection{跟踪器中目标候选的作用分析}
\label{dpeffectsec}
\begin{figure}[htb]
  \centering
  \subfloat[针对尺度适应力的准确率图]{%
    \includegraphics[height=8cm,width=10cm]{resultdpscale-1.pdf}}\hspace{-2.5cm}
  \newline
  \subfloat[针对尺度适应力的成功率图]{
    \includegraphics[height=8cm,width=10cm]{resultdpscale-2.pdf}}
  \caption{嵌入不同目标候选生成器后的尺度适应力对比}
  \label{resultdpscale}
\end{figure}

\begin{figure}[htb]
  \centering
  \subfloat[针对宽高比适应力的准确率图]{%
    \includegraphics[width=9cm]{resultdpas-1.pdf}}\hspace{-2.5cm}
  \newline
  \subfloat[针对宽高比适应力的成功率图]{
    \includegraphics[width=9.3cm]{resultdpas-2.pdf}}
  \caption{嵌入不同目标候选生成器后的宽高比适应力对比}
  \label{resultdpas}
\end{figure}

\begin{figure}[htb]
  \centering
  \subfloat[完整测试集上的准确率图]{%
    \includegraphics[height=8cm,width=10cm]{resultdpall-1.pdf}}\hspace{-2.6cm}
  \newline
  \subfloat[完整测试集上的成功率图]{
    \includegraphics[height=8cm,width=10cm]{resultdpall-2.pdf}}
  \caption{嵌入不同目标候选生成器后的整体性能对比}
  \label{resultdpall}
\end{figure}

\ref{generatoradaptsec}节中，通过将6个不同的目标候选生成器面向跟踪任务进行适配，并嵌入跟踪器中，得到了6个新的跟踪器。
这里将它们用各自所包含生成器进行命名。
此外，加上未使用目标候选的跟踪器（记为Without\_Proposal，也即是上一章的CKCF）以及KCFDPT，一共有8个跟踪器。
这8个跟踪器在OTB的``尺度变化''子集、``宽高比变化''子集和完整测试集上的运行结果（准确率图和成功率图）
分别如图\ref{resultdpscale}、图\ref{resultdpas}、和图\ref{resultdpall}所示。

根据表\ref{methods-comparison}中目标候选生成器所生成的目标候选质量排名，
EdgeBoxes、Geodesic和Baseline\_Gaussian依次取得了从高到低的前三名。
而余下的3个生成器，Bing、Objectness和Baseline\_Uniform都将生成类似质量的较差的目标候选。
再观察本小节的3个实验结果图，可以清晰地看出，该目标候选质量排名和对应跟踪器的准确性排名十分吻合。
因此可以得出结论：目标候选质量与嵌入目标候选生成器后的跟踪精度间存在着正相关关系。
从实验结果图还可以看出，不同目标候选生成器所带来的跟踪精度差别十分显著，
嵌入一些质量较差的目标候选生成器甚至会产生副作用，使得跟踪精度低于Without\_Proposal。
这一现象证明，目标候选在视觉物体跟踪中有着重要的作用。
要提升跟踪精度，必须选用质量较高的目标候选生成器，并进行有针对性的优化。

相比其它7个跟踪器，KCFDPT无论在尺度和宽高比适应力上（图\ref{resultdpscale}和\ref{resultdpas}），
还是在面对各种跟踪障碍的鲁棒性上（图\ref{resultdpall}），均是最优的。
这充分证明了本章优化后的EdgeBoxes是最适于跟踪任务的。
KCFDPT和Without\_Proposal间的明显性能差距也显示了优化后的EdgeBoxes所带来的巨大性能提升。
此外，KCFDPT相对于EdgeBoxes（KCFDP）的性能提升显示了本章背景抑制优化的有效性。
但是，这一性能提升在图\ref{resultdpall}中变得不够明显，原因在于背景抑制并不能解决所有的跟踪障碍，
例如``快速运动（Fast Motion）''将导致初步目标位置的判定不够准确，
``离开视野（Out of View）''将导致目标物体无法被完全包含在目标候选生成器的输入图像块中。

为了更进一步地分析不同目标候选生成器在跟踪器中的作用，
表~\ref{dpstat}给出了各个跟踪器在整个OTB测试集上的一些统计数据。
各个目标候选生成器在一帧中平均生成的候选数量是近似的，这保证了本节性能对比的公平性。
而目标候选在过滤前后的巨大数量差别，充分证明了目标候选过滤步骤的有效性。
即使是在低功耗CPU上运行，KCFDPT的平均跟踪速度也达到了20.4 FPS，足以说明其高效性。
此外，通过对比KCFDPT和EdgeBoxes（KCFDP）的跟踪速度，可以看出背景抑制优化带来的额外时间开销几乎是可忽略不计的。
值得注意的是，各跟踪器的跟踪速度不仅和目标候选生成速度有关，还与过滤后剩余的目标候选数目相关（需要再次进行辨别）。
因此Bing的跟踪速度甚至超过了两个基准方法。

\begin{table}[htb]
	\centering
	\caption{各个跟踪器在OTB测试集上的统计数据}
	\label{dpstat}
	\begin{tabular}{| p{1.3in} | p{0.9in}<{\centering} | p{0.9in}<{\centering} | p{0.9in}<{\centering} |}
		\hline
		\multicolumn{1}{ |p{1.3in}<{\centering}| }{嵌入了目标候选生成器的跟踪器} & 平均跟踪速度 (FPS) & 过滤前的平均目标候选数量 & 过滤后的平均目标候选数量 \\
		\hline
		KCFDPT & 20.4 & 103.34  & 4.43 \\
		\hline
		EdgeBoxes & 20.8  & 103.00  & 4.38 \\
		\hline
		Geodesic & 14.4 & 127.07  & 4.78 \\
		\hline
		Objectness & 6.5  & 104.95  & 1.37 \\
		\hline
		Bing & 30.9  & 133.22 & 2.32 \\
		\hline
		Baseline\_Uniform & 25.1  & 120.00  & 3.17 \\
		\hline
		Baseline\_Gaussian & 27.2  & 120.00  & 2.80 \\
		\hline
		Without\_Proposal & 112.2  & --  & -- \\
		\hline
	\end{tabular}
\end{table}

\subsection{跟踪器中目标候选的优化效果评测}
本小节中，KCFDPT将与不同的跟踪器进行对比。
对照组与上一章\ref{datasetcomponetsec}节相同，共包含34个跟踪器。
由于KCFDPT在准确率图和成功率图中的曲线趋势与KCFDP（图\ref{resultdpscale}、\ref{resultdpas}、\ref{resultdpall}中的EdgeBoxes）十分相似，且性能全面高于KCFDP，因此如果再在OTB测试集及其两个子集上进行基于统计图的对比，将显得较为冗余。
因此，这里将把OTB测试集进一步细分，获得具有不同尺度变化速度和程度，以及不同宽高比变化速度和程度的总共12个子集，
并在这12个子集上进行数值化的对比评测。
此外，为了测试KCFDPT的通用性，本小节还将在VOT 2014测试集上，进行额外的实验对比。

\subsubsection{数值化对比评测}
\label{numericalcompare}
相比基于统计图的对比，数值化的对比将更加细致，能够对KCFDPT的性能进行更深入的分析。
在上一章\ref{datasetcomponetsec}节中，根据一个固定的帧窗口（前30帧）和一个固定的宽高比变化阈值（$\sqrt{2}$），
14个具有``宽高比变化''障碍的视频序列被挑选出来。
为了进一步分析KCFDPT在不同的宽高比变化速度，以及不同的变化剧烈程度下的性能，
本节将通过调整上述帧窗口大小和宽高比变化阈值来进一步细分``宽高比变化''子集。
3个不同的帧窗口大小，即``$20\sim30$''、``$10\sim20$''、``$1\sim10$''，被用于将14个序列细分为慢速、中速、快速宽高比变化子集。
这里``$x\sim y$''意指在每一帧的前$x$帧到前$y$帧中进行宽高比对比。
类似地，3个宽高比相对变化区间，``$\sqrt{2}\sim1.5$''、``$1.5\sim1.6$''、``$1.6\sim\infty$''，被用于将
14个序列细分为低、中、高宽高比变化程度。
这里的``$x\sim y$''意指在某一前序帧中，相对宽高比的变化超过了$(1/x, x)$，但未超过$(1/y, y)$。
上述对``宽高比变化''子集的细分结果如表\ref{rate_level_division}(a)所示。

\begin{table}[htb]
	\centering
	\caption{对OTB测试集的进一步细分}
    \label{rate_level_division}
    \scalebox{1}{
    \subfloat[具有不同的宽高比变化速度和剧烈程度的视频序列子集]{
\scalebox{0.9}{
	\begin{tabu}{|>{\raggedright}m{1.85cm}|>{\raggedright}m{1.85cm}|>{\raggedright}m{1.85cm}|>{\raggedright}m{1.85cm}|>{\raggedright}m{1.85cm}|>{\raggedright}m{1.85cm}|}
		\hline
		\multicolumn{3}{|c|}{宽高比变化速度}                                     & \multicolumn{3}{c|}{宽高比变化剧烈程度}                                                                     \\ \hline
		\multicolumn{1}{|c|}{慢} & \multicolumn{1}{c|}{中} & \multicolumn{1}{c|}{快} & \multicolumn{1}{c|}{低} & \multicolumn{1}{c|}{中} & \multicolumn{1}{c|}{高} \\ \hline
		\textit{Skating1}          & \textit{Soccer}             & \textit{Matrix}            & \textit{Skating1}        & \textit{Soccer}             & \textit{Matrix}                   \\
		\textit{Freeman3}          & \textit{Shaking}            & \textit{Ironman}           & \textit{Shaking}         & \textit{Couple}             & \textit{Ironman}                  \\
		\textit{Freeman4}          & \textit{Couple}             & \textit{Walking2}          & \textit{Girl}            & \textit{Walking2}           & \textit{Skiing}                   \\
		\textit{MotorRolling}      & \textit{Girl}               & \textit{Walking}           & \textit{Freeman3}        & \textit{Walking}            & \textit{}                         \\
		\textit{Woman}             & \textit{}                   & \textit{Skiing}            & \textit{Freeman4}        & \textit{}                   & \textit{}                         \\
		\textit{}                  & \textit{}                   & \textit{}                  & \textit{MotorRolling}    & \textit{}                   & \textit{}                         \\
		\textit{}                  & \textit{}                   & \textit{}                  & \textit{Woman}           & \textit{}                   & \textit{}                         \\
		\hline
	\end{tabu}
	}
}
}
\scalebox{1}{
\subfloat[具有不同的尺度变化速度和剧烈程度的视频序列子集]{
\scalebox{0.9}{
		\begin{tabu}{|>{\raggedright}m{1.85cm}|>{\raggedright}m{1.85cm}|>{\raggedright}m{1.85cm}|>{\raggedright}m{1.85cm}|>{\raggedright}m{1.85cm}|>{\raggedright}m{1.85cm}|}
			\hline
			\multicolumn{3}{|c|}{尺度变化速度}                                            & \multicolumn{3}{c|}{尺度变化剧烈程度}                                         \\ \hline
			\multicolumn{1}{|c|}{慢} & \multicolumn{1}{c|}{中} & \multicolumn{1}{c|}{快} & \multicolumn{1}{c|}{低} & \multicolumn{1}{c|}{中} & \multicolumn{1}{c|}{高} \\ \hline
	        \textit{Crossing}         & \textit{David}              & \textit{Soccer}            & \textit{Boy}             & \textit{David}              & \textit{Soccer}           \\
			\textit{Walking2}         & \textit{Boy}                & \textit{Matrix}            & \textit{Crossing}        & \textit{Walking}            & \textit{Matrix}           \\
			\textit{Fleetface}        & \textit{Girl}               & \textit{Ironman}           & \textit{Walking2}        & \textit{}                   & \textit{Ironman}          \\
		    \textit{Freeman1}         & \textit{Walking}            & \textit{Skiing}            & \textit{Fleetface}       & \textit{}                   & \textit{Girl}             \\
			\textit{Freeman3}         & \textit{Freeman4}           & \textit{MotorRolling}      & \textit{Freeman1}        & \textit{}                   & \textit{CarScale}         \\
			\textit{Lemming}          & \textit{CarScale}           & \textit{}                  & \textit{Freeman3}        & \textit{}                   & \textit{Skiing}           \\
			\textit{}                 & \textit{}                   & \textit{}                  & \textit{Freeman4}        & \textit{}                   & \textit{MotorRolling}     \\
			\textit{}                 & \textit{}                   & \textit{}                  & \textit{Lemming}         & \textit{}                   & \textit{}                 \\ \hline
		\end{tabu}
	}
}
}

\end{table}

基于相似的方法，本节从OTB测试集中提取出具有不同尺度变化速度和不同尺度变化剧烈程度的视频序列，并组织成子集。
通过在每一帧的前30帧中对比目标物体边界框的面积，3个面积变化区间，``$1.6\sim1.8$''、``$1.8\sim2.0$''、``$2.0\sim\infty$''，
被分别用于从测试集中提取低、中、高尺度变化程度子集。
为了提取具有不同尺度变化速度的子集，本节使用3个帧窗口，``$20\sim30$''、``$10\sim20$''、``$1\sim10$''，
以及一个固定的面积变化区间``$1.6\sim\infty$''。
具有不同尺度变化速度和不同尺度变化剧烈程度的视频序列如表\ref{rate_level_division}(b)所示。

在这些细分后的子集上，排名前五的跟踪器的数值化跟踪精度如表\ref{per-seq-asp}和表\ref{per-seq-scale}所示。
表中给出的距离精度（DP）以20像素作为中心位置误差（CLE）阈值，
给出的重叠精度（OP）以$0.5$作为IoU阈值。
上述的阈值设置与PASCAL VOC\upcite{voc2007}物体检测测试集的要求是一致的。
两个表中，第一列中的跟踪精度是在所有被选入表\ref{rate_level_division}(a)或者表\ref{rate_level_division}(b)的
视频序列上进行平均而得到的。
而其它列中的数值化精度均是跟踪器在表\ref{rate_level_division}中的对应子集上取得的平均精度。
此外，在每个数值化跟踪精度之后，
还给出了各个跟踪器的``优势视频序列数量''（表示该跟踪器在多少个序列上取得了最优或者次优的跟踪精度）。
每一个子集中，最优和次优的精度分别用粗正体和粗斜体进行表示。

\begin{table}[htb]
	\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
	\centering
		\caption{不同宽高比变化速度和剧烈程度下的距离精度和重叠精度}
	\label{per-seq-asp}
	\scalebox{0.8}{
		\begin{tabu}{c l|l|l|l|l|l|l|l|}
			\cline{3-9}
			 & &   \multicolumn{1}{c|}{宽高比}         & \multicolumn{3}{c|}{宽高比变化速度}                                                          & \multicolumn{3}{c|}{宽高比变化程度}                                                        \\ \cline{4-9} 
			 & &  \multicolumn{1}{c|}{变化}    & \multicolumn{1}{c|}{慢}         & \multicolumn{1}{c|}{中}       & \multicolumn{1}{c|}{快}         & \multicolumn{1}{c|}{低}          & \multicolumn{1}{c|}{中}       & \multicolumn{1}{c|}{高}         \\ \hline   
			\multicolumn{1}{|l}{\multirow{5}{*}{\rotatebox{90}{\tabincell{c}{\textbf{距离}\textbf{精度}}}}} & \multicolumn{1}{|l|}{KCFDPT}            & \textbf{70.27\%, 9} & \textbf{78.92\%, 5} & \textbf{\textit{81.78\%, 1}} & \textbf{\textit{52.40\%, 3}} & \textbf{84.51\%, 6} & \textbf{\textit{82.54\%, 2}} & \textbf{\textit{20.67\%, 1}} \\ \cline{2-9}
			\multicolumn{1}{|l}{} &\multicolumn{1}{|l|}{SCM}               & 57.79\%, 8                        & 65.05\%, 2                        & 54.90\%, 1                        & \textbf{52.85\%, 5} & 72.38\%, 3                        & 59.55\%, 2                        & \textbf{21.41\%, 3} \\ \cline{2-9}
			\multicolumn{1}{|l}{} &\multicolumn{1}{|l|}{DSST}              & \textbf{\textit{66.01\%, 7}} & \textbf{\textit{76.56\%, 2}} & 71.92\%, 2                        & 50.73\%, 3                        & \textbf{\textit{82.19\%, 3}} & 73.79\%, 3                        & 17.88\% ,1                        \\ \cline{2-9}
			\multicolumn{1}{|l}{} &\multicolumn{1}{|l|}{SAMF}              & 57.58\%, 7                        & 61.03\%, 1                        & 61.33\%, 3                        & 51.13\%, 3                        & 58.47\%, 2                        & \textbf{85.31\%, 4} & 18.55\%, 1                        \\ \cline{2-9}
			\multicolumn{1}{|l}{} &\multicolumn{1}{|l|}{Without\_Proposal} & 59.52\%, 5                        & 62.47\%, 1                        & \textbf{82.64\%, 2} & 38.09\%, 2                        & 71.30\%, 2                        & 71.96\%, 2                        & 15.48\%, 1                        \\ \Xhline{1.25pt}
			\multicolumn{1}{|l}{\multirow{5}{*}{\rotatebox{90}{\tabincell{c}{\textbf{重叠}\textbf{精度}}}}} &\multicolumn{1}{|l|}{KCFDPT}            & \textbf{62.47\%, 7} & \textbf{71.15\%, 4} & \textbf{68.25\%, 3} & \textbf{\textit{49.18\%, 0}} & \textbf{78.38\%, 6} & \textbf{\textit{69.38\%, 1}} & \textbf{\textit{16.15\%, 0}} \\ \cline{2-9}
			\multicolumn{1}{|l}{} &\multicolumn{1}{|l|}{SCM}               & \textbf{\textit{50.95\%, 6}} & \textbf{\textit{50.62\%, 2}} & 53.11\%, 0                        & \textbf{49.55\%, 4} & \textbf{\textit{61.59\%, 2}} & 57.58\%, 1                        & \textbf{17.30\%, 3} \\ \cline{2-9}
			\multicolumn{1}{|l}{} &\multicolumn{1}{|l|}{DSST}              & 46.54\%, 8                        & 45.58\%, 3                        & 46.61\%, 2                        & 47.44\%, 3                        & 50.30\%, 4                        & 65.50\%, 3                        & 12.48\%, 1                        \\ \cline{2-9}
			\multicolumn{1}{|l}{} &\multicolumn{1}{|l|}{SAMF}              & 44.42\%, 6                        & 38.57\%, 1                        & 46.08\%, 3                        & 48.95\%, 2                        & 42.03\%, 2                        & \textbf{69.83\%, 3} & 16.13\%, 1                        \\ \cline{2-9}
			\multicolumn{1}{|l}{} &\multicolumn{1}{|l|}{Without\_Proposal} & 39.17\%, 3                        & 36.45\%, 0                        & \textbf{\textit{59.09\%, 1}} & 25.96\%, 2                        & 47.90\%, 0                        & 43.98\%, 1                        & 12.40\%, 2                        \\ \hline
		\end{tabu}
	}
\end{table}

% Please add the following required packages to your document preamble:
% \usepackage[table,xcdraw]{xcolor}
% If you use beamer only pass "xcolor=table" option, i.e. \documentclass[xcolor=table]{beamer}
\begin{table}[htb]
	\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
	\caption{不同尺度变化速度和剧烈程度下的距离精度和重叠精度}
	\label{per-seq-scale}
	\centering
	\scalebox{0.8}{
		\begin{tabular}{c l|l|l|l|l|l|l|l|}
			\cline{3-9}
			& &\multicolumn{1}{c|}{尺度}   & \multicolumn{3}{c|}{尺度变化速度}                                                                 & \multicolumn{3}{c|}{尺度变化程度}                                                                 \\ \cline{4-9} 
			& &    \multicolumn{1}{c|}{变化}   & \multicolumn{1}{c|}{慢}         & \multicolumn{1}{c|}{中}       & \multicolumn{1}{c|}{快}         & \multicolumn{1}{c|}{低}          & \multicolumn{1}{c|}{中}        & \multicolumn{1}{c|}{高}         \\ \hline
			\multicolumn{1}{|l}{\multirow{5}{*}{\rotatebox{90}{\tabincell{c}{\textbf{距离}\textbf{精度}}}}} &\multicolumn{1}{|l|}{KCFDPT}            & \textbf{67.43\%, 12} & 71.51\%, 4                        & \textbf{95.53\%, 6} & \textbf{28.84\%, 2} & \textbf{\textit{78.10\%, 6}} & \textbf{100.00\%, 2} & \textbf{45.94\%, 4} \\ \cline{2-9} 
			\multicolumn{1}{|l}{}&\multicolumn{1}{|l|}{SCM}               & 60.11\%, 10                        & \textbf{\textit{77.95\%, 4}} & 76.60\%, 3                        & 18.94\%, 3                        & 70.32\%, 4                        & \textbf{100.00\% ,2} & 37.05\%, 4                        \\ \cline{2-9}
			\multicolumn{1}{|l}{}&\multicolumn{1}{|l|}{DSST}              & \textbf{\textit{66.90\%, 12}} & 71.66\%, 4                        & \textbf{\textit{94.06\%, 5}} & \textbf{\textit{28.59\%, 3}} & \textbf{78.21\%, 6} & \textbf{100.00\%, 2} & 44.51\%, 4                        \\ \cline{2-9}
			\multicolumn{1}{|l}{}&\multicolumn{1}{|l|}{SAMF}              & 65.85\%, 11                        & \textbf{79.82\%, 4} & 83.60\%, 5                        & 27.80\%, 2                        & 75.59\%, 5                        & \textbf{100.00\%, 2} & \textbf{\textit{44.97\%, 4}} \\ \cline{2-9}
			\multicolumn{1}{|l}{}&\multicolumn{1}{|l|}{Without\_Proposal} & 56.60\%, 4                         & 59.00\%, 1                        & 80.39\%, 2                        & 25.19\%, 1                        & 59.62\%, 2                        & 99.68\%, 1                         & 40.85\%, 1                        \\ \Xhline{1.25pt}
			\multicolumn{1}{|l}{\multirow{5}{*}{\rotatebox{90}{\tabincell{c}{\textbf{重叠}\textbf{精度}}}}} &\multicolumn{1}{|l|}{KCFDPT}            & \textbf{62.47\%, 9}  & \textbf{\textit{71.85\%, 5}} & \textbf{90.43\%, 3} & 17.65\%, 1                        & \textbf{75.20\%, 6} & 97.18\%, 0                         & \textbf{37.99\%, 3} \\ \cline{2-9}
			\multicolumn{1}{|l}{}&\multicolumn{1}{|l|}{SCM}               & 56.08\%, 9                         & \textbf{76.82\%, 5} & 68.24\%, 0                        & 16.59\%, 4                        & \textbf{\textit{66.19\%, 5}} & 93.69\%, 0                         & 33.77\%, 4                        \\ \cline{2-9}
			\multicolumn{1}{|l}{}&\multicolumn{1}{|l|}{DSST}              & 52.68\%, 9                         & 58.65\%, 2                        & 74.68\%, 5                        & \textbf{19.13\%, 2} & 61.44\%, 4                        & \textbf{99.88\%, 2}  & 29.20\%, 3                        \\ \cline{2-9}
			\multicolumn{1}{|l}{}&\multicolumn{1}{|l|}{SAMF}              & \textbf{\textit{57.08\%, 9}}  & 68.12\%, 2                        & \textbf{\textit{78.61\%, 4}} & \textbf{\textit{18.00\%, 3}} & 65.67\%, 3                        & \textbf{\textit{97.76\%, 2}}  & \textbf{\textit{35.64\%, 4}} \\ \cline{2-9}
			\multicolumn{1}{|l}{}&\multicolumn{1}{|l|}{Without\_Proposal} & 39.04\%, 2                         & 45.03\%, 0                        & 53.65\%, 0                        & 14.32\%, 2                        & 48.18\%, 0                        & 52.78\%, 0                         & 24.67\%, 2                        \\ \hline
		\end{tabular}
	}
\end{table}

根据表\ref{per-seq-asp}，KCFDPT在所有的宽高比变化速度和剧烈程度下都是最有优势的。
但是，在表\ref{per-seq-scale}中，对于尺度变化，KCFDPT的优势有轻微下降，
原因在于SCM、DSST和SAMF也具备一定的尺度适应力。
它们的尺度适应策略在尺度变化较慢时（表\ref{per-seq-scale}中数值化精度的第2列）尤其有效。
此外，具有最剧烈宽高比变化程度（表\ref{per-seq-asp}的最后一列）和具有最快尺度变化速度（表\ref{per-seq-scale}中数值化精度的第4列）的视频序列恰好是OTB测试集中最难的，
因此表中的所有5个跟踪器都取得了很低的跟踪精度，
导致对应的精度排名代表性不佳。
具有中等尺度变化程度（表\ref{per-seq-scale}中数值化精度的第6列）的子集中仅包含了2个视频序列，因此其下的精度区分度也显得不足。
综上所述，综合考虑不同的尺度变化速度和程度，以及不同的宽高比变化速度和程度，
KCFDPT的整体适应力是最佳的，足以证明本章优化后的EdgeBoxes对于跟踪任务的适应性。

\subsubsection{VOT测试集上的对比}
\label{vot_test}
为了更加完整的评测，以及测试KCFDPT的通用性，
本节将在VOT 2014\upcite{vot2014}测试集上进行额外的实验。
VOT 2014包含25个视频序列，并且给出了自己的跟踪性能评价标准。
与OTB不同，VOT 2014测试集是逐帧标注跟踪障碍的（例如遮挡、亮度变化、大小变化等），
并且正确的跟踪结果是使用可旋转的边界框来表示的。
VOT 2014的性能评价标准也与OTB大不相同，
在一个跟踪器丢失目标后，VOT允许其进行重置，即从失败处附近开始，按照正确跟踪结果重新开始跟踪。
VOT根据两个方面来评价一个跟踪器的性能，即准确性和鲁棒性。
准确性按照IoU标准进行度量，类似于OTB中的重叠精度；鲁棒性按照跟踪器的失败重启次数进行度量。
VOT并不输出各个跟踪器的绝对准确性和鲁棒性，
而是给出各个跟踪器在所有参与对比的跟踪器中的相对排名。
此外，VOT还将进行两种实验：基准实验中，在第一帧和每次重启时，跟踪器按照正确跟踪结果进行初始化；
噪声实验中，跟踪器将按照随机扰动后的正确结果进行初始化。
在实际使用场景中，跟踪器在初始化时获得的目标状态通常都是足够准确的，因此本节仅进行基准实验。

VOT 2014除了提供测试数据集和评价标准，还提供了38个跟踪器在其上的运行结果。
本节注意到，VOT 2014中也附带了DSST和KCF的跟踪结果，但它们与本章在OTB上所使用的跟踪器不是同一版本。
为了对比的公平性，本节也把前面章节所使用的DSST和KCF版本加入了评测中，
分别记为DSST\_org和KCF\_org。
至于KCFDPT，除了必需的接口修改以外，本节不作任何修改和调优。
至此，在VOT 2014上进行对比评测的跟踪器一共有41个，其结果如表\ref{vot2014}所示。
为了显示清晰，表中只给出了VOT附带的38个跟踪器中的前五名，以及DSST\_org、KCF\_org和KCFDPT
的性能排名。
最优和次优的排名分别用粗正体和粗斜体进行了强调。

\begin{table}[htb]
	\centering
		\caption{VOT 2014上的测试结果}
	\label{vot2014}
	\scalebox{0.9}{
		\begin{tabular}{l c c c |c c c }
			& \multicolumn{3}{c|}{完整测试集（基准实验）}                                           & \multicolumn{3}{c}{大小变化（基准实验）}                                       \\ \cline{2-7} 
			& \multicolumn{1}{c}{准确性排名}               & 鲁棒性排名             & 综合排名               & 准确性排名              & 鲁棒性排名 & 综合排名               \\ \hline
			\multicolumn{1}{l|}{DSST}      & \textbf{1.83} & 4.67                        & \textbf{3.25} & \textbf{1.00} & 8.00                        & 4.50                        \\ \hline
			\multicolumn{1}{l|}{SAMF}      & \textbf{\textit{2.00}} & 5.00                        & \textbf{\textit{3.50}} & \textbf{1.00} & 10.00                       & 5.50                        \\ \hline
			\multicolumn{1}{l|}{KCF}       & 2.17                        & 5.00                        & 3.59                        & \textbf{1.00} & 10.00                       & 5.50                        \\ \hline
			\multicolumn{1}{l|}{DGT}       & 5.83                        & 5.50                        & 5.67                        & \textbf{1.00} & \textbf{2.00} & \textbf{1.50} \\ \hline
			\multicolumn{1}{l|}{PLT\_14}   & 5.83                        & \textbf{2.33} & 4.08                        & 3.00                        & \textbf{2.00} & \textbf{\textit{2.50}} \\ \hline
			\multicolumn{1}{l|}{DSST\_org} & 2.50                        & 7.17                        & 4.84                        & 3.00                        & 18.00                       & 10.50                       \\ \hline
			\multicolumn{1}{l|}{KCF\_org}  & 9.17                        & 12.17                       & 10.67                       & 8.00                        & 30.00                       & 19.00                       \\ \hline
			\multicolumn{1}{l|}{KCFDPT}    & 2.50                        & \textbf{\textit{4.50}} & \textbf{\textit{3.50}} & \textbf{1.00} & 10.00                       & 5.50                        \\ \hline
		\end{tabular}
	}

\end{table}

在整个测试集上和目标正在发生大小变化的帧上，KCFDPT表现出了和SAMF近似的性能。
这与前面章节在OTB上测得的结果很不相同，其原因应该在于VOT 2014的失败重启机制。
SAMF通过采样多个尺度略微不同的候选区域来适应目标物体的尺度变化，
因此能够在物体大小变化较慢或者不频繁时取得较好效果。
然而由于VOT的失败重启机制，当目标物体大小突然变化时，它也能通过重启继续跟踪目标。
在目标大小变化的帧上，DGT\upcite{dgt}和PLT\_14\upcite{vot2013}凭借很强的鲁棒性，
超过了SAMF和KCFDPT。
这样的结果并不奇怪，因为DGT和PLT\_14的物体描述分别是基于区块的和使用稀疏局部特征的，
因此它们的鲁棒性通常会强于使用全局描述的跟踪器。
最后，在完整的VOT 2014测试集上，KCFDPT获得了综合排名第二的成绩，并且大幅优于DSST\_org和KCF\_org，
这足以证明KCFDPT在跟踪任务中的通用性。

\subsection{参数敏感性分析}
\label{parameter-sensitivity}
在KCFDPT中，有部分参数是难以通过理论推导或者是根据其实际意义来获得最佳设置的，
它们也因此为称作``经验参数''。
为了分析这些参数的作用，本节将适度地遍历它们的不同设置，并进行参数敏感性分析，
遍历的结果还将同时证明本章和前一章中参数设置的有效性。
在考察一个特定的参数时，本节将在OTB测试集及其两个子集（``尺度变化''子集和``宽高比变化''子集）上，用它的不同值来运行KCFDPT，
而其它的参数设置全部保持和KCFDPT中的原设置一样。

需要注意的是，本节的参数遍历并不是如同训练神经网络那样，在高维参数空间中进行搜索。
那样的参数搜索通常会带来严重的``过拟合''问题。
本节中，各个参数都是被独立地考察的（未被考察的参数保持原设置不变），并且候选的参数值也相当稀疏。
这样的适度参数遍历将能够展示出不同参数设置的作用，同时还不会降低通用性。
作为一个证明，\ref{vot_test}节中，KCFDPT在VOT 2014上仍然可以取得很好的跟踪性能。

\begin{figure}[htb]
\centering
		\includegraphics[width=15cm]{parameter_sensitivity2.pdf}
	\caption{不同参数设置下的跟踪精度和速度}
	\label{parameter_sensitivity}
\end{figure}

本节将考察5个参数，通过遍历这些参数的不同设置所得到的结果如图\ref{parameter_sensitivity}所示。
5个参数分别是背景抑制的大小阈值（\ref{backsuppresssec}节中设置为$64\times64$，对应图\ref{parameter_sensitivity}(a1)和(a2)）、
尺度和宽高比检测窗口的尺度因子（\ref{wholeprocesssec}节中的$s^e$，对应图\ref{parameter_sensitivity}(b)）、
阻尼因子（公式\ref{kcfdp-damping}中的$\gamma$，对应图\ref{parameter_sensitivity}(c)）、
EdgeBoxes的最小面积因子（在公式\ref{EBfactor}中设置为$0.3$，对应图\ref{parameter_sensitivity}(d)）以及
EdgeBoxes的最大宽高比因子（在公式\ref{EBfactor}中设置为$1.5$，对应图\ref{parameter_sensitivity}(e)）。
在图\ref{parameter_sensitivity}中，参数的不同取值沿横坐标显示，纵坐标用于显示跟踪的精度（距离精度和重叠精度）
和速度（相对FPS，即根据每幅子图中的最高FPS归一化后的FPS）。
与准确率图和成功率图中的排名标准一样，这里的距离精度（DP）以20像素作为中心位置误差（CLE）阈值，
重叠精度（OP）按照曲线下面积（AUC）进行计算，即考虑了所有的IoU阈值。
但图\ref{parameter_sensitivity}(a2)是一个例外，它采用了更加严格的中心位置误差阈值（10像素）
和IoU阈值（0.7）。
图例中，后缀All、SV、ARV分别代表跟踪精度是在整个OTB测试集、``尺度变化''子集和``宽高比变化''子集上测得的。
而跟踪速度均是在整个OTB测试集上测得。
图中的最高和次高精度分别用 {\color[HTML]{FE0000} $\boldsymbol{\circ}$}和{\color[HTML]{3531FF} $\boldsymbol{\circ}$}
进行了标注，它们对应的值也在曲线末尾分别用 {\color[HTML]{FE0000}红色}和{\color[HTML]{3531FF}蓝色}给出。

如图\ref{parameter_sensitivity}(a1)所示，将背景抑制应用于大于$32\times32$（由于使用了对数坐标，对应于图中横坐标的$5$）
的图像块，看上去要略优于使用阈值$64\times64$（对应于图中横坐标的$6$）。
但是，当对跟踪精度的要求更加严格时（图\ref{parameter_sensitivity}(a2)），背景抑制大小阈值$64\times64$
变得明显更优，因此若考虑通用性，该阈值是最佳的。
在图\ref{parameter_sensitivity}(d)中，两个最小面积因子，$0.3$和$0.8$，看起来都是较好的选择。
但是考虑到以$0.3$作为参数值时的重叠精度明显更好，因此$0.3$应当是最佳选择。
至于图\ref{parameter_sensitivity}(b)、(c)和(e)中的其它3个参数，本章和上一章所采用的参数设置都能取得最高的跟踪精度。

对于跟踪速度而言，背景抑制的大小阈值几乎没有影响，原因在于本章的背景抑制步骤是极其高效的，几乎不占用跟踪时间。
越大的尺度和宽高比检测窗口应当给目标候选生成器来带越大的计算压力，并且会产生更多的目标候选。
但是，图\ref{parameter_sensitivity}(b)中，速度的下降趋势在尺度因子到达$1.4$后就停止了。
这说明目标候选的生成在跟踪过程中只占据少部分时间，并且上一章的目标候选过滤能够滤除大部分的目标候选，
仅余下恒定数量的可靠候选。
图\ref{parameter_sensitivity}(c)中的阻尼因子仅影响最终得到的目标位置和大小，因此对跟踪速度影响很小。
类似于尺度和宽高比检测窗口的尺度因子，EdgeBoxes中越小的最小面积因子（图\ref{parameter_sensitivity}(d)）
和越大的最大宽高比因子（图\ref{parameter_sensitivity}(e)）应当导致越慢的目标候选生成速度。
但是，两个子图中的跟踪速度对这两个参数均不敏感，
这再一次证明，相比整个跟踪过程，目标候选的生成速度是非常快的。


\section{小结}
本章承接上一章的内容，对跟踪器中``目标候选''的作用进行了分析，并对上一章的目标候选生成器进行了深入地优化。
通过将现有的目标候选生成器面向跟踪任务进行适配，
多个生成器被合理地嵌入了跟踪器中。
通过对比这些目标候选生成器在跟踪任务中的表现，
本章证明了目标候选的质量和跟踪精度间存在着正相关的关系，
同时也确认了本章对EdgeBoxes的背景抑制优化是十分有效的。
本章还对最终得到的跟踪器进行了更加充分的实验评测，
其结果表明，本章优化后的目标候选生成器，对于不同速度和剧烈程度的尺度和宽高比变化都有着很强的适应力，
且具有极佳的通用性。
在本章和前一章中，目标候选生成器都是作为密集采样运动模型的一个补充。
下一步的工作将考虑把密集采样运动模型和目标候选生成器进行整合，
以同时发挥密集采样的可靠性和目标候选的灵活性。
