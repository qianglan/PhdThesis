%*********************第四章******************
\chapter{基于OpenCL的TLD算法高性能实现}
\section{引言}
在前两章中，通过在算法层次上优化当前具有领先精度的跟踪器KCF，以及适用于视觉跟踪的目标候选生成器EdgeBoxes，并将两者有效结合起来，取得了令人满意的视觉跟踪性能。
但是，随着机器视觉应用对精度和鲁棒性的要求不断提高，跟踪器的结构正日趋复杂，计算负载与日俱增，高质量、高性能的跟踪器实现变得越来越关键。
这一点在视觉跟踪领域顶级竞赛VOT（Visual Object Tracking）中也得到了印证。作为第一届VOT竞赛，VOT2013~\upcite{vot2013}选取了16个视频序列，每个序列突出一个视觉跟踪中的难点（如遮挡，光照变化等）。首届获胜的跟踪器PLT~\upcite{plt}采用二值化特征作为目标描述，并用查找表的方式实现了线性分类器，因此其C++实现达到了169.59 FPS的极高速度。VOT2014~\upcite{vot2014}将视频序列扩充为25个，且标记目标物体的矩形框允许旋转，对跟踪器提出了更高难度的挑战。该届获胜的DSST~\upcite{dsst}由互相配合的两个相关滤波器构成，一个用于判断目标中心位置，一个用于判断最佳目标大小。结构的简洁性和相关滤波的低计算量使得其Matlab版本也能够做到实时处理（24 FPS）。VOT2015~\upcite{vot2015}的视频序列达到了60个，且难度大幅增加。为了应对挑战，MDNet~\upcite{mdnet}采用了专门面向视觉跟踪的6层卷积神经网络（CNN），并按照高斯分布大量采样不同位置、不同大小的局部图像进行检测。尽管MDNet在精度和鲁棒性上取得了第一名，但是由于它的计算量很大，实现（Matlab+MatConvNet）又较为粗糙，仅能达到1 FPS的跟踪速度，无法满足实时在线跟踪的要求。

由此可见，在跟踪算法日益复杂的趋势下，为了保证跟踪算法的实用性，或者说为了提高视觉跟踪对计算复杂性的容忍度，研究跟踪算法的高性能实现十分必要。
这里的高性能实现，和``高性能计算''属同一范畴，意指在实现过程中针对硬件体系结构特征，充分发挥计算设备/平台的计算能力。
通过分析体系结构和高性能计算的发展可以看出，并行化无疑是解决高性能实现问题的关键。利用多核并行、向量指令、流水化等并行手段，可以充分发挥通用处理器（CPU）的计算能力。
除了CPU这一经典计算设备，当前包含两类甚至多类计算设备的异构计算平台正方兴未艾。从嵌入式平台（如Nvidia Jetson~\upcite{jetson}）到超级计算机（如天河-1A~\upcite{top500}），CPU+GPU的组合已成为一种潮流。要发挥异构平台的计算潜力，除了充分开发算法中的可并行部分以外，
如何同时发挥CPU和GPU的性能，以及如何控制两者间的协作和数据传输等是高性能实现面临的又一挑战。

本章将以TLD\upcite{tld, tldjournal}跟踪算法为例，以OpenCL\upcite{oclspec}作为编程模型，阐述视觉跟踪算法在异构平台下的高性能实现所需的关键技术和面临的问题挑战。严格来讲，TLD算法并非是一个单纯的视觉跟踪算法，而是一个``长时间鲁棒跟踪框架''。它在传统跟踪算法中引入了独立的学习和检测模块，将跟踪-学习-检测三部分有机结合起来：跟踪模块仅根据前一帧判断目标在当前帧中的位置；学习模块构建一个可靠的目标描述，并不断更新它；检测模块在整个帧图像中找出可能包含目标的区域，用以修正跟踪结果。这样的结构，使得TLD比传统跟踪器鲁棒得多，且能适应长时间的目标跟踪。此外，除了TLD本身提供的3个模块算法，各个模块都可以自由替换为具有类似功能的算法，如将跟踪模块替换为KCF跟踪器，将学习模块和检测模块分别替换为RCNN\upcite{fastrcnn, fasterrcnn}的训练过程和检测过程等。因此，研究TLD的高性能实现兼具实用性和理论研究价值，未来应用前景广阔。
另一方面，相比其它并行编程模型如CPU上的OpenMP、GPU上的CUDA等，OpenCL是跨平台的，其具备的功能移植性可以使得同一程序（如同一跟踪算法或者同一算法模块）不经修改地在不同异构设备上正确地执行，从而方便地利用异构计算平台下的各种计算设备。因此OpenCL是在异构计算平台下进行高性能跟踪算法实现的一个合适选择。

本章内容安排如下：第2、3节分别介绍OpenCL编程模型和TLD跟踪算法流程；第4节介绍TLD检测模块的第一部分\pozhehao Fern随机森林的高性能实现；第5节介绍检测模块的第二部分\pozhehao 最邻近（Nearest Neighbor，NN）分类器的高性能实现；第6节介绍学习模块中的瓶颈部分的高性能实现；第7节对高性能实现的效果进行评测；最后在第8节进行本章总结。

\section{OpenCL编程模型}
介绍编程模型

\section{TLD跟踪算法}
翻译简化TLD论文的核心部分。
重画结构图、数据流图，跟待并行优化的模块对应起来。
性能瓶颈分析。

\section{Fern随机森林的高性能实现}
算法流程
\subsection{像素特征提取的并行化}
\subsection{分类过程的并行化}
\subsection{与跟踪器重叠执行}

\section{最邻近分类器的高性能实现}
\subsection{算法流程}
\subsection{分类过程的并行化}

\section{学习过程的高性能实现}
TLD学习过程的流程
\subsection{重叠率计算和负样本提取的并行化}
\subsection{正样本提取的并行化}

\section{实验评测与分析}
\subsection{Kernel性能评测与分析}
在CPU、GPU上，纯Kernel的执行时间；性能移植性问题

算上数据重组、传输等额外开销的执行时间

\subsection{整体性能评测与分析}
全部Kernel在CPU上执行；全部Kernel在GPU上执行（可重叠）；各Kernel在适合的设备上执行（最优性能）

\section{小结}