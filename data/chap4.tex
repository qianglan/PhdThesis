%*********************第四章******************
\chapter{基于OpenCL的TLD算法高性能实现}
\section{引言}
在前两章中，通过在算法层次上优化当前具有领先精度的跟踪器KCF，以及适用于视觉跟踪的目标候选生成器EdgeBoxes，并将两者有效结合起来，取得了令人满意的视觉跟踪性能。
但是，随着机器视觉应用对精度和鲁棒性的要求不断提高，跟踪器的结构正日趋复杂，计算负载与日俱增，高质量、高性能的跟踪器实现变得越来越关键。
这一点在视觉跟踪领域顶级竞赛VOT（Visual Object Tracking）中也得到了印证。作为第一届VOT竞赛，VOT2013\upcite{vot2013}选取了16个视频序列，每个序列突出一个视觉跟踪中的难点（如遮挡，光照变化等）。首届获胜的跟踪器PLT\upcite{plt}采用二值化特征作为目标描述，并用查找表的方式实现了线性分类器，因此其C++实现达到了169.59 FPS的极高速度。VOT2014\upcite{vot2014}将视频序列扩充为25个，且标记目标物体的矩形框允许旋转，对跟踪器提出了更高难度的挑战。该届获胜的DSST\upcite{dsst}由互相配合的两个相关滤波器构成，一个用于判断目标中心位置，一个用于判断最佳目标大小。结构的简洁性和相关滤波的低计算量使得其Matlab版本也能够做到实时处理（24 FPS）。VOT2015\upcite{vot2015}的视频序列达到了60个，且难度大幅增加。为了应对挑战，MDNet\upcite{mdnet}采用了专门面向视觉跟踪的6层卷积神经网络（CNN），并按照高斯分布大量采样不同位置、不同大小的局部图像进行检测。尽管MDNet在精度和鲁棒性上取得了第一名，但是由于它的计算量很大，实现（Matlab+MatConvNet）又较为粗糙，仅能达到1 FPS的跟踪速度，无法满足实时在线跟踪的要求。

由此可见，在跟踪算法日益复杂的趋势下，为了保证跟踪算法的实用性，或者说为了提高视觉跟踪对计算复杂性的容忍度，研究跟踪算法的高性能实现十分必要。
这里的高性能实现，和``高性能计算''属同一范畴，意指在实现过程中针对硬件体系结构特征，充分发挥计算设备/平台的计算能力。
通过分析体系结构和高性能计算的发展可以看出，并行化无疑是解决高性能实现问题的关键。利用多核并行、向量指令、流水化等并行手段，可以充分发挥通用处理器（CPU）的计算能力。
除了CPU这一经典计算设备，当前包含两类甚至多类计算设备的异构计算平台正方兴未艾。从SoC芯片（如Qualcomm Snapdragon 835\upcite{snapdragon}）到嵌入式平台（如Nvidia Jetson\upcite{jetson}），甚至到超级计算机（如天河-1A\upcite{top500}），CPU+GPU的组合已成为一种潮流。要发挥异构平台的计算潜力，除了充分开发算法中的可并行部分以外，
如何同时发挥CPU和GPU的性能，以及如何控制两者间的协作和数据传输等是高性能实现面临的又一挑战。

本章将以TLD\upcite{tld, tldjournal}跟踪算法为例，以OpenCL\upcite{oclspec}作为编程模型，阐述视觉跟踪算法在异构平台下的高性能实现所需的关键技术和面临的问题挑战。严格来讲，TLD算法并非是一个单纯的视觉跟踪算法，而是一个``长时间鲁棒跟踪框架''。它在传统跟踪算法中引入了独立的学习和检测模块，将跟踪-学习-检测三部分有机结合起来：跟踪模块仅根据前一帧判断目标在当前帧中的位置；学习模块构建一个可靠的目标描述，并不断更新它；检测模块在整个帧图像中找出可能包含目标的区域，用以修正跟踪结果。这样的结构，使得TLD比传统跟踪器鲁棒得多，且能适应长时间的目标跟踪。此外，除了TLD本身提供的3个模块算法，各个模块都可以自由替换为具有类似功能的算法，如将跟踪模块替换为KCF跟踪器，将学习模块和检测模块分别替换为RCNN\upcite{fastrcnn, fasterrcnn}的训练过程和检测过程等。因此，研究TLD的高性能实现兼具实用性和理论研究价值，未来应用前景广阔。
另一方面，相比其它并行编程模型如CPU上的OpenMP\upcite{openmp}、GPU上的CUDA\upcite{cudaspec}等，OpenCL是跨平台的，其具备的功能移植性可以使得同一程序（如同一跟踪算法或者同一算法模块）不经修改地在不同异构设备上正确地执行，从而方便地利用异构计算平台下的各种计算设备。因此OpenCL是在异构计算平台下进行高性能跟踪算法实现的一个合适选择。

本章内容安排如下：第2、3节分别介绍OpenCL编程模型和TLD跟踪算法流程；第4节介绍TLD检测模块的第一部分\pozhehao Fern随机森林的高性能实现；第5节介绍检测模块的第二部分\pozhehao 最邻近（Nearest Neighbor，NN）分类器的高性能实现；第6节介绍学习模块中的瓶颈部分的高性能实现；第7节对高性能实现的效果进行评测；最后在第8节进行本章总结。

\section{OpenCL编程模型}
\label{oclmodels}
当前，异构计算平台，即包含了多种异构计算设备（CPU、GPU、DSP等）的计算系统，已经非常普及。用传统方法编写高性能程序已较为困难\pozhehao
面向多核CPU的编程通常使用共享存储模型，主要开发多核间的线程级并行；而面向GPU的编程通常关心复杂的存储层次和数据级并行。
巨大的编程方式差异，导致程序员难以用一种代码来开发多种异构设备的计算能力。

OpenCL（Open Computing Language，开放计算语言） 是一个专门面向异构系统通用目的的编程模型标准。苹果公司于2008年6月首次提出，Khronos工作组于2010年6月正式发布。它的设计初衷就是面向异构计算平台，提供一个统一的编程模型。程序员们只需编写一个程序，就可以方便地利用异构平台的所有计算资源。为了达到这一目的，OpenCL屏蔽了硬件设备的体系结构差异，并用四个抽象模型来描述编程方式和其它细节。

\begin{figure}[htb]
  \centering
  \includegraphics[width=12cm]{ocl_platform_mem_model}
  \caption{OpenCL的平台模型和存储模型\upcite{cell}}
  \label{oclplatformandmem}
\end{figure}

\begin{compactitem}
\item \textbf{平台模型（Platform Model）}
\end{compactitem}

平台模型是OpenCL的抽象低层硬件结构。通过将硬件结构抽象地更为低层，暴露出更多的硬件细节，从而留出更多的编程和优化灵活性；而抽象性又屏蔽了体系结构差异，保证了程序的可移植性。

如图\ref{oclplatformandmem}所示，OpenCL的平台由宿主处理器（Host Processor）和与之互联的一个或者多个计算设备（Compute Device）构成。
每个计算设备又包含一个或者多个计算单元（Compute Unit），而一个计算单元又包含一个或多个处理单元（Processing Element）。
处理单元作为最细粒度的计算承载单位，是一个抽象的标量处理器。

\begin{figure}[htb]
  \centering
  \subfloat[上下文和命令队列\upcite{oclppt}]{%
    \label{comandqueue}
    \includegraphics[height=4.5cm]{commandqueue}}\hspace{0.2cm}
  \subfloat[多维索引空间]{
    \label{ndrange}
    \includegraphics[height=4.2cm]{ndrange}}
  \caption{OpenCL的执行模型}
  \label{oclexecution}
\end{figure}

\begin{compactitem}
\item \textbf{执行模型（Execution Model）}
\end{compactitem}

一个OpenCL程序包括两大部分\pozhehao 宿主程序（Host Program）和Kernel程序（或称内核程序）。

宿主程序用C或者C++编写，运行于宿主处理器之上，通过提交命令（Command）的方式来控制计算设备中的处理单元进行计算，或是控制宿主处理器和计算设备之间的数据传输。
如图\ref{comandqueue}所示，宿主程序会定义一个上下文（Context），上下文中包含了可用的计算设备、待执行的Kernel程序、存储空间等信息。
宿主程序还会为每一个计算设备分配一个或者多个命令队列（Command Queue，或者Queue），并向命令队列中添加命令。随后命令队列就会调度命令进行执行。
命令有三种类型：执行Kernel程序，数据传输，以及同步。

Kernel程序实质上是一个函数，用OpenCL C语言编写，执行于计算设备之上。宿主程序通过提交一个执行Kernel的命令，来启动Kernel程序在计算设备上的执行。
一个Kernel程序有众多的执行实例，对应于一个抽象的多维（一维到三维）索引空间（NDRange Index Space）。
一个Kernel的执行实例对应一个工作项（Work-Item），它是索引空间中的一个最细粒度点，代表着Kernel的一次执行，并根据其在空间中的位置被赋予一个全局索引值（Global ID）。每个工作项都执行相同的Kernel程序，但是由于索引值的不同，各自的执行路径和访问的数据也会不同。
多个相邻工作项组成一个工作组（Work-Group），是对索引空间的更粗粒度分解。根据在索引空间中的位置，工作组也会被赋予一个组索引值（Group ID）。而每个工作组内的工作项，还会根据其组内位置被赋予局部索引值（Local ID）。
OpenCL规定，一个工作组执行于一个计算单元之上，且同一工作组内的工作项是并发执行在计算单元中的处理单元上的。
如图\ref{ndrange}所示，为一个三维的索引空间。该空间包含了$3\times2\times2$个工作组，而每个工作组包含$2\times2\times2$个工作项。

\begin{compactitem}
\item \textbf{存储模型（Memory Model）}
\end{compactitem}

OpenCL的存储模型定义了四个独立的存储空间，分别位于不同的抽象硬件层次之上，且跟执行模型紧密相关。
如图\ref{oclplatformandmem}所示，全局存储（Global Memory）位于计算设备中，任何工作组中的任何工作项都可以读写其中的数据。
常量存储（Constant Memory）是全局存储的一部分，但是其中数据只能被读出而不能被修改。
计算设备还可能提供用以提升全局存储和常量存储性能的高速缓存（Data Cache）。
局部存储（Local Memory）通常位于计算单元之中，仅属于某一个工作组，只能被该工作组中的工作项访问，而对其它工作组来说是不可见的。
私有存储（Private Memory）通常位于处理单元内，是一个工作项所私有的，其它工作项都不可见。

宿主程序可以通过提交数据传输类的命令，来实现宿主处理器的主存（Main Memory）和计算设备的全局存储/常量存储间的数据传输。

\begin{compactitem}
\item \textbf{程序模型（Programming Model）}
\end{compactitem}

这里的程序模型，指的是并行程序的实现方式。OpenCL支持两类并行程序模型，数据并行和任务并行，以及这两类的混合编程。

数据并行是指一个指令序列同时作用于多个存储元素（数据）之上，它是通过定义执行模型中的多维索引空间来实现的。
所有工作项执行相同的Kernel程序，即同一个指令序列；而各个工作项在索引空间中有着不同的索引值，导致根据索引值的访存会访问到不同的数据。
这样一来，同一Kernel程序将同时处理不同数据，实现数据并行。

任务并行是指不同指令序列的同时执行。
实现任务并行，通常是通过在一个或者多个命令队列中，添加多个Kernel执行命令来实现的。


\section{TLD跟踪算法}
\label{sectldalgo}
TLD的命名来自于跟踪（Tracking）-学习（Learning）-检测（Detection）三部分的首字母。
将这三部分有机结合，正是TLD相比于传统跟踪算法的最大区别。
如图\ref{tld}所示，跟踪模块负责计算目标物体在连续两帧间的运动，并提供一个目标候选位置。
它假设目标物体在连续两帧间的运动幅度较小，且目标总是可见的。因此当目标被遮挡或是离开视野时，跟踪模块通常会失效且无法自行恢复。
检测模块将每一帧都看作是独立的，并在整个帧图像中进行搜索检测，从而提供一到多个可能包含目标物体的候选位置。
因此当跟踪模块失效时，检测模块可以重启跟踪。
学习模块会综合考虑跟踪和检测的结果，以最终确定目标物体的位置。
此外，它还会为检测模块提供新的训练数据，以不断提升检测的准确度。

\begin{figure}[htb]
  \centering
  \includegraphics[width=7cm]{tld}
  \caption{TLD跟踪算法的三大部分}
  \label{tld}
\end{figure}

TLD的形式化流程如算法\ref{tldalgo}所示。
更具体地，TLD算法在逐帧运行之前需进行初始化。
初始化的首要任务是构造网格（Grid），即大量的边界框（Bounding Box）。
网格通过用不同的尺度和步长来扫描整幅帧图像得到，与当前帧内容无关，仅与帧大小和目标初始尺度相关。
逐帧运行过程中，检测模块将检测网格中的每一个边界框，找出其中可能包含目标物体的。


\begin{algorithm}[htbp]
  \caption{TLD跟踪算法（对于第$i$帧）}
  \label{tldalgo}
  \algsetup{linenosize=\scriptsize}
  \footnotesize
  \begin{algorithmic}[1]
    \REQUIRE $ $ \\ 当前帧图像$frame[i]$，\\ 前一帧图像$frame[i-1]$，\\ 目标物体在前一帧中的位置（边界框）$lastBB$；
    \ENSURE $ $ \\ 目标物体在当前帧中的位置（边界框）$currentBB$；
    \STATE $trackedBB \leftarrow Tracker( frame[i-1], frame[i], lastBB )$
    \\ $\bullet$ 跟踪模块根据目标物体在前一帧中的位置，计算其在当前帧中的位置，得到$trackedBB$，失效时$trackedBB$为NULL；
    \STATE $detectedBBs \leftarrow Detector( frame[i] )$
    \\ $\bullet$ 检测模块在当前帧中检测出所有可能包含目标物体的边界框，存入$detectedBBs$；
    \STATE $clusteredBBs \leftarrow Cluster( detectedBBs )$
    \\ $\bullet$ 将$detectedBBs$中互相靠近的边界框合并为单个框，存入$clusteredBBs$；
\IF{$trackedBB \neq $ NULL}
    \FOR{\textbf{each} $clusteredBB$ \textbf{in} $clusteredBBs$}
    	\IF{ $Overlap( clusteredBB, trackedBB )  < 0.5$ \AND $NNConf( clusteredBB )  > NNConf( trackedBB )$}
    	\STATE $confidentBBs \leftarrow clusteredBB$ 
    	\ENDIF
    \ENDFOR
    \\ $\bullet$ 从$clusteredBBs$中选出距离$trackedBB$较远，但是置信度更高的边界框，存入$confidentBBs$;
    \IF{ $Sizeof( confidentBBs ) = 1$ }
    \STATE $currentBB \leftarrow confidentBBs[0]$ 
    \\ $\bullet$ 如果$confidentBB$是唯一的，则认为跟踪模块出错，重启跟踪模块；
	\ELSE 
	\STATE $currentBB \leftarrow WeightedAverage( trackedBB, detectedBBs )$ 
	\\ $\bullet$ 否则，以$trackedBB$为主，将$trackedBB$和它附近的$detectedBBs$进行加权平均，得到当前目标位置；
    \ENDIF
    \\ $\bullet$ 跟踪模块有效时，$trackedBB$和$detectedBBs$共同决定$currentBB$；
\ELSE
	\IF{ $Sizeof( clusteredBBs )  = 1$ }
	\STATE $currentBB \leftarrow clusteredBBs[0]$
	\ENDIF
	\\ $\bullet$ 跟踪模块失效时，若存在唯一的$clusteredBB$，则用它来重启跟踪模块；
\ENDIF

	\IF{ $trackedBB \neq $ NULL \AND $Validated( trackedBB ) $ }
    \STATE $ Learn( currentBB, frame[i] )  $
    \ENDIF
    \\ $\bullet$ 若$trackedBB$通过验证，则学习模块根据$currentBB$提取正负样本，训练检测模块。
  \end{algorithmic}
\end{algorithm}

函数$Tracker()$的主要部分是LK（Lucas-Kanade）光流跟踪\upcite{lkoptflow, lkoptflow2}，属于跟踪模块。
LK光流跟踪算法会运行两次，第一次用于估计目标物体从$frame[i-1]$到$frame[i]$的运动；第二次逆向运行，根据估计到的$frame[i]$中位置，
计算物体在$frame[i-1]$中的原位置。
通过对比$lastBB$和两次LK光流计算的结果，可以判断出LK光流跟踪是否成功，即跟踪模块是否有效。
%如果LK光流跟踪成功，还需利用最邻近分类计算其结果位置的置信度（$NNConf()$）。

%只有置信度高于阈值时，跟踪模块才有效，$Tracker()$才会输出$trackedBB$。

函数$Detector()$主要包括两部分，Fern随机森林\upcite{fern}分类和最邻近分类（Nearest Neighbor Classifier），均属于检测模块。
首先，Fern随机森林将作用于网格中的大量边界框，并得出响应值。该响应值反映了边界框恰好包围目标物体的概率。
随后，响应值高于阈值的边界框将通过最邻近分类，计算出置信度（$NNConf()$）。
最邻近分类的模型为一组正负样本图像块，置信度的计算过程为将输入图像块与正负样本逐一进行相似度对比。
这里的相似度使用NCC（Normalized Cross-Correlation，归一化互相关）\upcite{ncc}来度量，
而置信度由输入图像块与正样本的相似程度，以及它与负样本的不相似程度共同决定。
置信度高于阈值的边界框才能作为$Detector()$的输出。
函数$Cluster()$将$Detector()$输出的边界框进行聚类，把互相靠得太近的多个边界框合并为一个，以进一步减少数目。

目标物体在当前帧中的位置最终由学习模块来确定。如果跟踪模块有效，则综合考虑跟踪和检测的结果：
若$clusteredBBs$中存在且仅存在一个置信度高于$trackedBB$的边界框，则认为跟踪模块出错，用检测结果替代跟踪结果；
否则，将跟踪结果与它附近的检测结果进行加权平均，作为最终目标位置。
如果跟踪模块失效，未避免歧义，当且仅当$clusteredBBs$中有唯一边界框时，用来作为最终目标位置。

学习模块还负责决定进行学习的时机，即跟踪结果足够可靠时\pozhehao 跟踪模块有效，且$trackedBB$通过了验证。
$Validated()$函数在两种情况下认为验证通过：$trackedBB$经过最邻近分类得到的置信度足够高；或者在某一历史帧中置信度足够高，
且从那时起跟踪模块从未失效或出错。
学习过程$Learn()$分为两步，提取正负样本和再训练检测模块。
提取正负样本前，需要先计算网格中所有边界框与$currentBB$的重叠率（$Overlap()$）。
对于Fern随机森林，选取重叠率低且响应值较高的边界框作为负样本，即``难反例挖掘（Hard Negative Minning）''；
同时选取重叠率高的边界框，并进行随机旋转缩放，作为正样本。
对于最邻近分类器，从$detectedBBs$中选取重叠率低于阈值的边界框作为负样本；
同时以重叠率最高的边界框作为唯一正样本。
再训练Fern随机森林的过程，即是更新每一棵随机树的叶节点权值的过程。通过记录落入每一个叶节点的正负样本总数，更新其权值。
再训练最邻近分类器的过程，即是验证正负样本是否与当前模型冲突（正样本的置信度太低，或负样本置信度太高）的过程。
将冲突的正负样本加入模型中就完成了更新。

通过测试TLD算法的官方串行版本OpenTLD\upcite{opentld}，以及借鉴H-TLD\upcite{htld}中的性能分析，
同时考虑到OpenCL会带来的额外开销，本章将以OpenTLD为基础，对其中的计算密集部分和性能瓶颈部分用OpenCL进行高性能实现。
这些部分包括Fern随机森林分类，最邻近分类，学习过程中的重叠率计算、正负样本提取。
LK光流跟踪部分也是计算密集的，但由于OpenTLD所依赖的OpenCV\upcite{opencv}库已提供了OpenCL版本的实现，因此这里不再重复实现。
至于其它部分，有的计算量太小（如确定最终目标位置时，$clusteredBBs$中边界框数量通常很少），有的不适于用OpenCL并行化（如再训练过程中，计算量小且分支过于密集）。

\section{Fern随机森林的高性能实现}
在进行Fern随机森林分类之前，OpenTLD先对网格中的所有边界框进行一次方差过滤，以减少输入随机森林的边界框数量。
边界框对应的图像块的灰度值方差被计算出来，若该方差低于初始帧中目标物图像块的方差，那么该边界框将被过滤掉。
虽然网格中边界框很多，但由于采用了``积分图（Integral Image）''方法，方差过滤十分高效，计算量较小。

如\ref{sectldalgo}节所述，即使加入了过滤步骤，Fern随机森林仍将作用于大量边界框，因此必须十分高效。
TLD算法中，用于分类的特征是基于``像素对比''生成的，即根据边界框提取出图像块，然后在图像块中按照预定模式采样13对像素点，并进行灰度值对比。如果用$0$和$1$来表示对比结果，则13对像素点的对比结果可用一个二进制向量表示，即Fern特征向量。
上述过程被称作特征提取，如图\ref{fernfig}中的``特征提取''部分所示。

\begin{figure}[htb]
  \centering
  \includegraphics[width=13cm]{fernfig}
  \caption{Fern随机森林分类的流程}
  \label{fernfig}
\end{figure}

由于网格中的边界框有着不同的尺度大小，TLD为每一个尺度定义了10种采样像素点对的模式，每一种采样模式都定义了13个点对的不同采样位置。
因此，每一个边界框通过特征提取后都会得到10个13位的Fern特征向量。
为了对这些特征向量进行分类，TLD针对每一种采样模式（即每一个Fern特征向量）构造一棵随机树，总共10棵随机树构成了Fern随机森林。
随机树的叶节点被赋予权值，代表着边界框包含目标物体的概率。
每个Fern特征向量经过对应随机树的分类后，都会落入该随机树的一个叶节点中。
将10个随机树叶节点的权值进行平均，即得到Fern随机森林的响应值。
上述过程即是Fern随机森林的分类过程，如图\ref{fernfig}中的``分类过程''部分所示。

\subsection{特征提取的并行化}
\label{featureextsec}
特征提取过程的输入为当前帧图像、网格、候选边界框索引、以及像素点对的采样模式；输出为所有候选边界框对应的Fern特征向量。
%在利用OpenCL进行特征提取前，需要对输入数据进行重构。

在本章的高性能实现中，帧图像的灰度值被存储在一个一维数组中。
网格在初始化时就构造好，为一个一维数组，每5个相邻元素代表一个边界框，分别是$\{BBx, BBy, BBw, BBh, scale\_id\}$，即左上角横、纵坐标、宽、高和尺度索引。
因为网格数组在整个跟踪过程中不会变动，因此将它放入OpenCL的常量存储中，供多个Kernel重复使用，而无需每次都进行分配和释放。
候选边界框索引是方差过滤步骤的输出，为一维数组，每个元素（$BBid$）都代表着一个候选边界框在网格数组中的位置。
在OpenTLD中，像素点对的采样模式也是一维数组，每4个相邻元素代表一个点对，记为$\{x_1, y_1, x_2, y_2\}$，即两个点在边界框内的坐标。
一种采样模式需要13个点对，而每一种尺度有10种采样模式，考虑所有尺度（最多为21种），采样模式数组中共有$scale\_num
\times10\times13\times4$个元素。
为了更高效的访存，本章将不同采样点的横、纵坐标连续存储，即将$\{x^1_1, y^1_1, x^1_2, y^1_2, ...,x^n_1, y^n_1, x^n_2, y^n_2,\}$
转换为$\{x^1_1, ..., x^n_1, y^1_1, ... , y^n_1, x^1_2, ..., x^n_2, y^1_2, ..., y^n_2\}$。
类似网格数组，采样模式数组也不会变动，因此放入OpenCL的常量存储。

特征提取的计算过程为，从候选边界框索引数组中读出边界框索引，根据该索引在网格数组中读出对应边界框的信息（左上角坐标和尺度索引）。
根据尺度索引访问采样模式数组，得到所需采样的$10\times13$对点在边界框内坐标。
将边界框内坐标和边界框左上角坐标叠加，即得到采样点在图像中的坐标。
最后根据图像中坐标，进行像素点采样对比，构造Fern特征向量。
图\ref{fernext}展示了一次像素点对比，即一个Fern向量中的一位的产生过程。

\begin{figure}[htb]
  \centering
  \includegraphics[width=15cm]{fernext}
  \caption{特征提取的流程}
  \label{fernext}
\end{figure}

特征提取的OpenCL并行实现采用一维的索引空间。
一个工作项负责一对采样点的图像中坐标计算、灰度值提取、灰度值对比，即执行一次图\ref{fernext}所示流程。
一个工作组包含130个工作项，负责生成一个边界框的所有（10个）Fern特征向量。
因此一个工作组执行完毕后，每13个相邻工作项需要将各自的像素对比结果整合为一个特征向量。
最后，工作组的数量应当和候选边界框数量相同。
对应的Kernel程序核心代码如表\ref{fernextcode}所示。
第6$\sim$9行中，由于重构了采样模式数组，局部索引值（\texttt{local\_id}）连续的工作项将访存连续的存储空间，从而实现了高效的合并访存（Coalesced Memory Access）。
第13行声明了局部存储数组，用于工作项间像素对比结果的高效共享。
最后，由每13个工作项的第一个工作项，负责将对比结果整合为Fern特征向量，写入全局存储中（第18$\sim$22行）。


\begin{table}
\caption{特征提取的Kernel程序}
\label{fernextcode}
\begin{lstlisting}[language=C++, basicstyle=\ttfamily\footnotesize]
__kernel void FernFeatureExtract( __global uchar* img, __constant int* grid, __global int* BB_ids, __constant uchar* sample_patterns, __global int* fern_features,  ... )
{
	...
	BB_id = BB_ids[group_id];
	scale_id = grid[BB_id*5+4];
	x1 = sample_patterns[scale_id*130*4*0+local_id] + grid[BB_id*5]; 
	y1 = sample_patterns[scale_id*130*4*1+local_id] + grid[BB_id*5+1]; 
	x2 = sample_patterns[scale_id*130*4*2+local_id] + grid[BB_id*5]; 
	y2 = sample_patterns[scale_id*130*4*3+local_id] + grid[BB_id*5+1]; 
	pixel1 = img[y1*img_width+x1];
	pixel2 = img[y2*img_width+x2];

	__local int comp_result[130];
	comp_result[local_id] = (pixel1>pixel2) << (12-(local_id%13));
	barrier(CLK_LOCAL_MEM_FENCE);

	...
	if( local_id%13 == 0 )
	{
		fern_feature = comp_result[local_id] | comp_result[local_id+1] | ... | comp_result[local_id+12];
		fern_features[group_id*10+local_id/13] = fern_feature;
	}
}
\end{lstlisting}
\end{table}

\subsection{分类过程的并行化}
\label{fernclassifysec}
获得每一个边界框的10个Fern特征向量后，需要将它们输入随机森林，获得响应值。
从表\ref{fernextcode}的第20行可以看出，保存像素对比结果的特征向量实际上是一个13位二进制整数，
因此高效实现中无需真正建立树结构来逐一判断特征向量的每一元素，
而是采用查找表的方式实现。
13位二进制整数一共有$2^{13}=8192$个可能值，因此可以将随机树实现为8192项的表，每一表项存储一个叶节点的权值。
由于随机森林有10棵树，需分配10个这样的表。
通过将特征向量看做表索引，对对应表进行查表，即可得到对应树的叶节点权值。
对于一个边界框，通过利用它的10个特征向量查找对应的10个表，再将得到的10个权值相加，即可得到响应值。

\begin{table}
\caption{分类过程的Kernel程序}
\label{fernclassifycode}
\begin{lstlisting}[language=C++, basicstyle=\ttfamily\footnotesize]
__kernel void FernClassify( __global int* fern_features, __global float* leaf_weights, __global float* fern_responses, ... )
{
	...
	tree_id = local_id%10;
	BB_id = group_id*20 + local_id/20;

	...
	__local float share_weights[200];	
	fern_feature = fern_features[BB_id*10+tree_id];
	share_weights[local_id] = leaf_weights[tree_id*8192+fern_feature];
	barrier(CLK_LOCAL_MEM_FENCE);

	if( ... && local_id % 10 == 0 )
	{
		fern_response = share_weights[local_id+0] + share_weights[local_id+1] + ... + share_weights[local_id+9];
		fern_responses[BB_id] = fern_response;
	}
}
\end{lstlisting}
\end{table}

分类过程的Kernel程序核心代码见表\ref{fernclassifycode}。程序的主要输入为Fern特征向量数组和叶节点权值数组，输出为每个边界框的响应值。
Fern特征向量数组即是\ref{featureextsec}节的Kernel程序输出，因此该数组可以在全局存储里直接重用。
将随机森林所对应的10个查找表连接在一起，组成了叶节点权值数组，它按顺序存储着$8192\times10$个叶节点权值。
由于每次训练会导致叶节点权值更新，因此该数组需要从主存中拷贝。
当OpenCL程序在GPU上运行时，工作组中的工作项数目太少会导致严重性能下降。
因此，本实现中的一个工作项负责用一个Fern特征向量查表，一个工作组包含200个工作项，即负责20个边界框的响应值计算。
工作项查表的过程就是一个间接访存的过程（表\ref{fernclassifycode}，第9、10行）。
通过使用局部存储（\texttt{share\_weights}，第8行），间接访存得到的权值可以被工作组高效共享。
因为每10个连续工作项计算同一个边界框的10个叶节点权值，所以它们中的第一个工作项负责将权值累加，计算出响应值（第13$\sim$17行）。

\subsection{与跟踪器重叠执行}
\label{detecttrackoverlapsec}
LK光流跟踪和Fern随机森林分类是完全独立的，可以重叠执行。
表\ref{lkferncode}为将光流跟踪和随机森林分类重叠执行的OpenCL宿主程序片段。
由于在每一帧中，经过方差过滤后的边界框数目（\texttt{BB\_num}）是不同的，
因此候选边界框索引数组（\texttt{BB\_ids}）、Fern特征向量数组（\texttt{fern\_features}）、
边界框响应值数组（\texttt{fern\_responses}）的长度也会变化，
需要重新创建存储对象，并传输数据（第2、3行）。
帧图像（\texttt{img}）和叶节点权值数组（\texttt{leaf\_weights}）的内容会变化，但是长度不变，因此可直接从主存传输（写入）到OpenCL全局存储（第6、7行）。
输入数据准备完毕后，将两个Kernel程序（\texttt{FernFeatureExtract}和\texttt{FernClassify}）的执行命令加入命令队列（第8、9行），随后再将Kernel的执行结果读出到主存（第10、11行）。
值得注意的是，无论是数据传输还是Kernel执行，上述过程在调用相关OpenCL API时均使用非阻塞版本，即是说将命令写入到命令队列后立即返回，而不是等待命令执行完毕。
写入命令后，命令队列会自动地调度其中的命令在OpenCL计算设备上执行，不再需要干预。
得益于这种机制，在传输数据和执行Kernel程序时，宿主程序无需等待即可调用LK光流跟踪函数进行跟踪（第13行），
从而实现LK光流跟踪和Fern随机森林分类的重叠执行。

LK光流跟踪执行完毕后，还需确认命令队列中的命令是否全部执行完毕（第15行），若未执行完毕，则还需阻塞等待。
最后，释放第2、3行创建的存储对象（第16、17行），以便在处理下一帧时重新创建。

\begin{table}
\caption{LK光流跟踪和Fern随机森林分类的重叠执行}
\label{lkferncode}
\begin{lstlisting}[language=C++, basicstyle=\ttfamily\footnotesize]    
  ...
  TLDCL.CreateMemBufferFernFeatureExtract ( BB_ids, BB_num, fern_features, BB_num*10 );
  TLDCL.CreateMemBufferFernClassify ( fern_responses, BB_num );
  TLDCL.SetKernelArgFernFeatureExtract( );
  TLDCL.SetKernelArgFernClassify( );
  TLDCL.WriteBufferFernFeatureExtract(  img, img.rows*img.cols );
  TLDCL.WriteBufferFernClassify( leaf_weights, 8192*10 );
  TLDCL.EnqueueKernelFernFeatureExtract( );
  TLDCL.EnqueueKernelFernClassify( );
  TLDCL.ReadBufferFernFeatureExtract( fern_features, BB_num*10 );
  TLDCL.ReadBufferFernClassify( fern_responses, BB_num );
    
  LKtrack(img_previous, img_current, lastBB, trackedBB);
    
  TLDCL.SyncCommandQueue(  );
  TLDCL.ReleaseMemObjectFernFeatureExtract( BB_ids, fern_features );
  TLDCL.ReleaseMemObjectFernClassify( fern_responses );
  ...
\end{lstlisting}
\end{table}


\section{最邻近分类器的高性能实现}
在完成Fern随机森林分类后，每个候选边界框的响应值都被计算出来。
只有响应值高于阈值，且排名前100的边界框，才能进入下一步最邻近分类，以计算其包含目标物体的置信度。

\subsection{算法流程}
TLD的最邻近分类算法较为直接。
最邻近分类器维护了两组图像块，即正样本和负样本，它们通常被称作分类器的模型。
分类器首先根据待分类边界框在帧图像中提取对应的图像块，然后将该图像块与模型中的图像块进行一一对比，计算它们的相似度。
在正样本中，输入图像块必然与某图像块最为相似，记它们的相似度为$maxP$。
同理，输入图像块与负样本图像块的最大相似度记为$maxN$。
该边界框的置信度即可按下式算出：
\begin{equation}
\label{nnconfeq}
NNConf = \frac{1-maxN}{2-maxP-maxN} .
\end{equation}
显然，一个边界框的置信度，跟对应图像块与正样本的相似度正相关，跟对应图像块与负样本的相似度反相关。

如\ref{tldalgo}节中所述，这里的相似度是两个图像块的NCC（归一化互相关），其原本定义如下。
对于两幅图像，输入图像$\mathbf{f}$和模板图像$\mathbf{t}$，首先将它们的灰度图保存为二维浮点数组，即每个像素点的灰度用一个$0\sim1$间的浮点数表示。
%然后，将两个二维数组中的所有元素减去各自数组的平均值，即计算归一化灰度。
然后，两幅图像的NCC计算公式为：
\begin{equation}
\label{ncceq}
NCC = \frac{ \sum_{x,y}\mathbf{f}(x, y)\mathbf{t}(x, y) }{ \sqrt{\sum_{x,y}\mathbf{f}(x, y)^2\sum_{x,y}\mathbf{t}(x, y)^2} } ，
\end{equation}
其中$(x, y)$代表像素的横纵坐标。
TLD算法对NCC进行了细微修改。为了避免光照亮度的影响，所有像素的灰度值都会减去所在图像块的平均灰度值。
因此，像素点的灰度不再是归一化的，而可能是正数或者负数。
为了保证NCC的归一化，计算公式修改为：
\begin{equation}
\label{ncceq2}
NCC = \frac{1}{2}( \frac{ \sum_{x,y}\mathbf{f}(x, y)\mathbf{t}(x, y) }{ \sqrt{\sum_{x,y}\mathbf{f}(x, y)^2\sum_{x,y}\mathbf{t}(x, y)^2} } + 1 ).
\end{equation}

\subsection{分类过程的并行化}
一个边界框的最邻近分类过程分为两个步骤\pozhehao 第一步计算对应图像块与每一个样本图像块的NCC，第二步找出$maxP$和$maxN$并计算置信度。
由于有多个边界框需要分类，第一步中需计算的NCC总数目为：边界框数目$\times$样本图像块数目。
考虑到每一次NCC计算需要遍历两个图像块，第一步的计算量将很大，亟需高性能并行化。
而因为边界框数目至多为100个，第二步的计算量会较小，且主要为归约操作（提取最大值），因此不适于用OpenCL进行并行化（归约操作需要大量分支和同步）。
基于上述考虑，本节仅对第一步，即所有NCC的计算，用OpenCL并行化实现。第二步仍然放在宿主程序中处理。

OpenTLD中，最邻近分类器的模型中的图像块大小为$15\times15$，因此根据边界框提取的图像块也会缩放到$15\times15$。
从公式\ref{ncceq2}可以看出，NCC的计算结果与图像块的像素存储方式和像素访问顺序无关。
因此，为了使用OpenCL进行并行化，本节把所有边界框对应图像块的灰度值连续地存储在一个一维数组（\texttt{patches}）中。
这样一来，该数组中每$15\times15=225$个连续相邻元素就是一个输入图像块。
同理，本节也把模型中的正负样本图像块连续地存储在一个一维数组（\texttt{p\_n\_samples}）中，
且正样本存储在前，负样本存储在后。这样只需记录正、负样本图像块的数目，就能区分某一元素属于正样本还是负样本。
上述两个一维数组即是NCC计算的输入。

\begin{figure}[htb]
  \centering
  \includegraphics[width=9cm]{nccfig}
  \caption{NCC计算的OpenCL索引空间}
  \label{nccfig}
\end{figure}

NCC计算的OpenCL实现使用三维索引空间，如图\ref{nccfig}所示（注：图中的两组图像块是分别连续存储在两个一维数组中的，这里为了显示清晰将各个图像块分开展示）。
一个工作组负责计算一个边界框对应图像块和一个样本图像块的NCC，因此工作组在$\{x, y, z\}$三个维度上的数目设置为$\{1, $边界框数目$, $样本图像块数目$\}$。
%其中$patch\_num$为边界框数目，$p\_n\_sample\_num$为样本图像块数目。
每个工作项负责一个像素位置，即计算两个图像块中同一位置处的灰度值平方和乘积，因此一个工作组内的工作项数目为$\{225, 1, 1\}$。
故整个三维索引空间的工作项数目是$\{225, $边界框数目$, $样本图像块数目$\}$。
根据公式\ref{ncceq2}，将各个像素位置处的计算结果进行累加是不可避免的。
为了实现高效的累加操作，本节将采用树形归约。
由于树形归约要求元素个数为2的次方，因此本节将工作组内工作项数目填充为$\{256, 1, 1\}$，整个索引空间的工作项数目变为$\{256, $边界框数目$, $样本图像块数目$\}$。

\begin{table}
\caption{NCC计算的Kernel程序}
\label{ncccode}
\begin{lstlisting}[language=C++, basicstyle=\ttfamily\footnotesize]    
__kernel void NCC( __global float* patches, __global float* p_n_samples, int p_n_sample_num, __global float* nccs )
{		
    ...
    if ( local_X_id < 225 ) 
    {
        patch_pixel = patches[group_Y_id*225+local_X_id];
        sample_pixel  = p_n_samples[group_Z_id*225+local_X_id];
    }
    else
    {
        patch_pixel = 0;
        sample_pixel  = 0;
    }
    
    __local float patch_squares[256];
    __local float sample_squares[256];
    __local float patch_sample_products[256];
    patch_squares[local_X_id] = patch_pixel * patch_pixel;
    sample_squares[local_X_id] = sample_pixel * sample_pixel;
    patch_sample_products[local_X_id] = patch_pixel * sample_pixel;	
    barrier(CLK_LOCAL_MEM_FENCE);
    
    for( int offset = local_X_size/2; offset > 0; offset >>= 1 ) 
    {
        if ( local_X_id < offset ) 
        {
            patch_squares[local_X_id] = patch_squares[local_X_id+offset] + patch_squares[local_X_id];
            sample_squares[local_X_id] = sample_squares[local_X_id+offset] + sample_squares[local_X_id];
            patch_sample_products[local_X_id] = patch_sample_products[local_X_id+offset] + patch_sample_products[local_X_id];
        }
        barrier(CLK_LOCAL_MEM_FENCE);
    }
	
    if( local_X_id == 0 )
    {	
        square_sum_product = pow( patch_squares[local_X_id]*sample_squares[local_X_id], 0.5 );
        nccs[group_Y_id*p_n_sample_num+group_Z_id] = (patch_sample_products[local_X_id]/square_sum_product + 1) * 0.5;
    }
}
\end{lstlisting}
\end{table}

NCC计算的Kernel程序核心代码见表\ref{ncccode}。
首先，每个工作项根据各自在索引空间中的位置提取像素灰度值（第4$\sim$13行）。
如果是用于填充的工作项，则灰度值置为0，以不影响结果正确性。
由于位置连续的工作项会访问位置连续的全局存储，这里的访存将是高效的合并访存。
第15$\sim$21行计算出公式\ref{ncceq2}中的$\mathbf{f}(x, y)\mathbf{t}(x, y) $、$\mathbf{f}(x, y)^2$以及$\mathbf{t}(x, y)^2$，
并放入局部存储中，以便进行高效累加。
23$\sim$32行进行树形归约，每次循环都将两个工作项的计算结果进行叠加，共需$\log_2256=8$次循环。
最后，每个工作组的第一个工作项负责利用累加结果，计算出NCC，并存入全局存储中（第34$\sim$38行）。
在计算出每个边界框对应的图像块和每个样本图像块之间的NCC后，所有NCC值被传回到宿主程序，由宿主程序负责第二步的置信度（$NNConf$）计算。

\section{学习过程的高性能实现}
\label{learnalgosec}
如\ref{sectldalgo}节中所述，当宿主程序整合了检测模块和跟踪模块的结果，确定了当前帧中的目标物体位置（$currentBB$），并决定在当前帧进行学习后，
将进入TLD算法的学习过程。
学习过程分为两个步骤。
第一步为提取正负样本，即计算出网格中的所有边界框与$currentBB$的重叠率，然后根据重叠率和Fern随机森林响应值来选取边界框作为正负样本。
第二步为再训练检测模块，即更新Fern随机森林的叶节点权值和最邻近分类器的模型。
第一步中的网格包含了数量巨大的边界框（例如，对于$320\times240$的帧图像将产生60000多个边界框），
逐个计算重叠率并考察响应值将带来巨大的时间开销。
而作为第二步的输入，正、负样本数量通常较少（如训练随机森林的正样本通常为10个，负样本为分类出错的边界框，更为稀少），
故计算量不大，且多为分支操作。
因此，本节仅针对第一步进行基于OpenCL的高性能并行化，而第二步仍然由宿主程序负责。

\subsection{重叠率计算和负样本提取的并行化}
这里的重叠率等价于第\ref{chapbmvc}、\ref{chapijcv}章中所使用的IoU（Intersection over Union），即两个边界框的交集面积除以并集面积。
待提取的负样本为重叠率低于阈值，但Fern随机森林响应值较高的边界框，即分类出错的边界框。
为了提高效率，重叠率的计算和负样本的提取可以在同一个Kernel程序中完成，也就是说在计算出重叠率后，若低于阈值，则检查其响应值，判断是否属于负样本。

显然，重叠率计算和负样本提取的输入为网格、当前目标物体位置（$currentBB$）和Fern随机森林响应值；
输出为网格中的所有边界框与$currentBB$的重叠率，以及负样本集合。
与特征提取的Kernel程序（表\ref{fernextcode}和图\ref{fernext}）不同，本节中每个工作项负责网格中一个边界框的重叠率计算。
若网格中的边界框仍然按照$\{ ..., BBx_i, BBy_i, BBw_i, BBh_i, scale\_id_i, ... \}$的形式存储在一维数组中，
那么位置连续的工作项在访问同一边界框参数（如$BBx$）时，会访问到间断的存储空间，无法进行合并访存。
由于网格是在初始化时构建的，整个跟踪过程中无需更改，因此在构建原网格数组的同时还可以构造一个以不同方式存储边界框的一维数组，
其内容为$\{BBx_1, ..., BBx_n, BBy_1, ..., BBy_n, BBw_1, ..., BBw_n, BBh_1, ..., BBh_n\}$，称为重构网格数组。
重构网格数组将代替原网格数组作为输入网格，它的构造也只需进行一次，开销可忽略不计。
Fern随机森林的响应值可以重用\ref{fernclassifysec}节的结果数组（\texttt{fern\_responses}），
但是需要插入被方差过滤滤掉的边界框响应值（置为$0.0$）。
由于负样本的数目不确定，且OpenCL中不同工作组内的工作项无法同步，因此采用标记数组来作为输出的负样本集合。
标记数组的长度等于网格中边界框数目，若其中某元素对应的边界框为负样本，则置1，否则置0。

重叠率计算和负样本提取的OpenCL并行实现较为直接，采用一维索引空间。
每一个工作项负责从重构网格数组中提取一个边界框，计算它与$currentBB$的重叠率。
若重叠率低于阈值，则检查响应值数组中对应的响应值，判断是否是负样本。
为了提高OpenCL设备的占用率，将512个工作项组成一个工作组。因此总的工作项数量需要从网格中边界框数量填充为512的倍数。
对应的Kernel程序核心代码如表\ref{overlapcode}所示。
第4$\sim$12行提取了用于重叠率计算的边界框，均可以合并访存。
第15$\sim$23行计算出IoU并存入全局存储中。
最后，25$\sim$30行检查响应值，判断对应边界框是否是负样本。

\begin{table}
\caption{重叠率计算和负样本提取的Kernel程序}
\label{overlapcode}
\begin{lstlisting}[language=C++, basicstyle=\ttfamily\footnotesize]    
__kernel void GetOverlapAndNegativeSample( __constant int* grid_reorg, __global int* currentBB,  __global float* fern_responses, __global float* overlaps, __global uchar* negative_tags )
{		
	...
	int box1x = currentBB[0];
	int box1y = currentBB[1];
	int box1w = currentBB[2];
	int box1h = currentBB[3];
	
	int box2x = grid_reorg[global_id];
	int box2y = grid_reorg[global_id+grid_BB_num];
	int box2w = grid_reorg[global_id+grid_BB_num*2];
	int box2h = grid_reorg[global_id+grid_BB_num*3];
	...
	
	if ( overlap != 0.0 ) {
	    intersec_x =  min(box1x+box1w, box2x+box2w) - max(box1x, box2x);
	    intersec_y =  min(box1y+box1h, box2y+box2h) - max(box1y, box2y);
	    intersec_area = intersec_x * intersec_y;
	    area1 = box1w*box1h;
	    area2 = box2w*box2h;
	    overlap = intersec_area / (area1+area2-intersec_area);
	}
	overlaps[global_id] = overlap;
	
	if ( global_id < grid_BB_num ) {
	  if ( overlap < low_overlap && fern_responses[global_id]>=high_response )
	    negative_tags[global_id] = 1;
	  else
	    negative_tags[global_id] = 0;
	}
}
\end{lstlisting}
\end{table}

\subsection{正样本提取的并行化}
OpenTLD中，学习过程所需的正样本为10个具有最高重叠率的边界框，因此提取正样本的过程就是搜索重叠率前10名的边界框的过程。
虽然该过程是一个典型的归约过程，计算量小且分支较多，但是由于网格中边界框数量巨大，
使用OpenCL并行化仍然可以大幅提高对存储带宽的利用，提升整体性能。

为了搜索重叠率前10的边界框，本节的OpenCL Kernel程序将循环执行10次，每次获取一个边界框在网格数组中的索引位置。
OpenCL索引空间设置为一维，其中的工作项总数与网格中的边界框数目相同。
每个工作项负责读取一个边界框的重叠率，并与工作组中其它工作项进行对比。
1024个工作项组成一个工作组，工作组内将进行树形归约，得到组内具有最大重叠率的边界框索引，并将该索引写入全局存储中。
各个工作组得到的边界框索引将传回宿主程序，由宿主程序再次归约，获得当前具有最大重叠率的边界框。
上述过程等价于将重叠率数组分段，每一段包含1024个边界框的重叠率。
然后在段内和段间进行两步归约，得到最大重叠率。
如图\ref{positivesample}所示，Kernel程序的输入为上一节获得的重叠率数组（\texttt{overlaps}），输出为各个工作组（即各个重叠率数组段）中具有最大重叠率的边界框索引。
宿主程序进行第二次规约后，找出当前具有最大重叠率的边界框并加入正样本中。
显然，若不加修改地再次执行Kernel程序，仍然会得到同一个边界框。
解决该问题的最简单方式就是将重叠率数组中对应的边界框重叠率置为最小值（$0.0$）。
为了避免在宿主程序中修改重叠率数组，然后再次传输到OpenCL计算设备，
本节把``当前最大重叠率边界框索引''也作为一个Kernel输入参数。
Kernel程序的第一步就是根据该索引，将重叠率数组对应元素置为0，然后再进行归约。

\begin{figure}[htb]
  \centering
  \includegraphics[width=12cm]{positivesample}
  \caption{正样本提取流程}
  \label{positivesample}
\end{figure}

正样本提取的Kernel程序核心代码如表\ref{positivesamplecode}所示。
第4行申请一个局部存储数组\texttt{overlaps\_local}，用于保存每次重叠率对比后得到的较高重叠率。
第5行申请的局部存储数组与\texttt{overlaps\_local}对应，用于保存\texttt{overlaps\_local}中每个重叠率对应的边界框索引。
第7$\sim$10行根据输入的``当前最大重叠率边界框索引''，将重叠率数组中的对应元素置为$0.0$。
值得注意的是，第10行的同步语句只作用于各个工作组内的工作项，因此第8行对全局存储数组\texttt{overlaps}的修改可能滞后于某些工作组的归约过程。
但是，被置为$0.0$的\texttt{overlaps}元素只可能被一个工作组用于归约，且负责置$0.0$的工作项正好属于该工作组（由第7行保证），
故这里只需工作组内同步就可以保证各个工作组的归约结果正确。
第12$\sim$14行将重叠率数组段拷贝到局部存储，并将对应的边界框索引填入\texttt{BB\_ids\_local}。
第16$\sim$27行是树形归约过程，每一次循环都将并行对比\texttt{overlaps\_local}中的两个元素，
并记录较高的重叠率和对应的边界框索引。
最后，各个工作组内具有最大重叠率的边界框索引将被写入全局存储中（第29$\sim$31行）。

\begin{table}
\caption{正样本提取的Kernel程序}
\label{positivesamplecode}
\begin{lstlisting}[language=C++, basicstyle=\ttfamily\footnotesize]    
__kernel void GetPositiveSample( __global float* overlaps, int current_top_BB_id, __global int* top_BB_id_in_group )
{			
    ...
    __local float overlaps_local[1024];
    __local int BB_ids_local[1024];

    if ( global_id == current_top_BB_id ) {
        overlaps[current_top_BB_id] = 0.0;
    }
    barrier(CLK_LOCAL_MEM_FENCE);

    overlaps_local[local_id] = overlaps[global_id];
    BB_ids_local[local_id] = global_id;
    barrier(CLK_LOCAL_MEM_FENCE);

    for ( int offset = local_size/2; offset > 0; offset >>= 1) 
    {
        if ( local_id < offset ) 
        {
            if ( overlaps_local[local_id] < overlaps_local[local_id+offset] )
            {
                   BB_ids_local[local_id] = BB_ids_local[local_id+offset];
                   overlaps_local[local_id] = overlaps_local[local_id+offset];
            }
        }
        barrier(CLK_LOCAL_MEM_FENCE);
    }

    if ( local_id == 0 ) {
        top_BB_id_in_group[group_id] = BB_ids_local[0];
    }
}
\end{lstlisting}
\end{table}

全局存储数组\texttt{top\_BB\_id\_in\_group}将被传回宿主程序，由宿主程序进行再次归约，得到当前最大重叠率边界框。
该边界框的索引将作为参数之一，再次调用Kernel程序，直到获取到10个正样本。
如\ref{learnalgosec}节开头所述，完成正、负样本的提取后，检测模块的再次训练不适于用OpenCL并行化，将交由宿主程序负责。
至此，整个TLD算法基于OpenCL的高性能实现已介绍完毕。

\section{实验评测与分析}
本章TLD算法高性能实现的部分可视化运行结果如图\ref{tldvisualsample}所示。
图\ref{tldvisualsample}中，从上至下，选用的视频序列依次为\textit{Car}、\textit{Jumping}、\textit{David}和\textit{Panda}。
序列\textit{Car}显示了TLD算法在目标离开视野、遮挡这两类情况下，仍然能够准确跟踪目标。
序列\textit{Jumping}主要展示了TLD对于目标快速移动和运动模糊的适应力。
\textit{David}序列中，光照变化剧烈，TLD算法展现了很高的鲁棒性。
\textit{Panda}序列主要突出了TLD算法对于目标物体非刚性形变的适应能力。

\begin{figure}[htb]
  \centering
  \includegraphics[width=13cm]{tldvisualsample}
  \caption{TLD算法高性能实现的部分运行结果}
  \label{tldvisualsample}
\end{figure}

作为高性能实现的评测，本章的实验将主要针对运行效率。
对比基准选用OpenTLD，输入测试序列选用\textit{Car}。
实验的硬件平台为典型桌面异构计算平台：CPU为Intel i7-5500U，采用Broadwell架构，双核四线程，2.4GHz，关闭睿频；
GPU为Nvidia GTX 960M，采用Maxwell一代架构，CUDA计算能力5.0，包含640个流处理器，处理器频率1096MHz，显存2GB，带宽80GB/s；
主存为16GB DDR3-1600 SDRAM，双通道，理论峰值带宽为25.6GB/s。
实验的软件环境采用Linux操作系统，发行版本为Ubuntu 16.04，内核版本为4.4，编译器为gcc/g++ 4.8。
CPU的OpenCL驱动和运行时采用Intel OpenCL 1.2 Driver\upcite{intelocl}，所支持的OpenCL版本为2.0；
GPU的OpenCL驱动和运行时包含在CUDA工具中，CUDA驱动版本为8.0，运行时版本为7.5，所支持的OpenCL版本为1.2。
因此，为了保证OpenCL实现的可移植性，本章的OpenCL代码均按照OpenCL 1.2标准编写。
整个TLD实现还依赖OpenCV库，版本为2.4.13。

\subsection{Kernel性能评测与分析}
本节首先评测各个Kernel的运行效率。
使用OpenCL进行高性能实现的Kernel一共有5个，分别是：
Fern特征提取（FernFeatureExtract），Fern随机森林分类过程（FernClassify），
最邻近分类过程的NCC计算（NCC），学习过程的重叠率计算和负样本提取（GetOverlapAndNegativeSample），
以及正样本提取（GetPositiveSample）。

由于OpenCL的移植性，上述Kernel可正确运行在多种设备上，且宿主程序可在运行时为各个Kernel指定计算设备。
通过将\textit{Car}作为输入序列，并指定所有Kernel在CPU上运行，可统计出各个Kernel在CPU上的时间开销。
为了保证时间测量准确，这里利用OpenCL命令队列的事件（Event）机制来记录Kernel的执行时间。
该执行时间仅为执行过程所需时间，不包括数据传输、Kernel启动等额外开销。
由于输入的视频序列含有大量帧图像，且Kernel一次执行的时间与图像内容有关，本节将Kernel在所有帧中的执行时间进行累加，
得到各Kernel在跟踪过程中的总执行时间，作为其时间开销。
整个TLD跟踪过程共运行3次，各个Kernel的最终时间开销为3次统计的平均值。
同理，使用相同输入序列，且指定所有Kernel在GPU上运行，可获得各个Kernel在GPU上的时间开销。
作为对比基准，本节还提取了OpenTLD中对应于各个Kernel的代码段，并同样按照上述方法统计了这些代码段的时间开销。

\begin{table}[htb]
\centering
\begin{minipage}[t]{0.81\linewidth}
\caption{各Kernel的时间开销对比}
\label{tldkerneltime}
\begin{tabular*}{\linewidth}{|l|c|c|c|c|c|}
\hline
\backslashbox{计算设备}{Kernel}  & FFE\footnote{FernFeatureExtract} & FC\footnote{FernClassify} & NCC     & GONS\footnote{GetOverlapAndNegativeSample} & GPS\footnote{GetPositiveSample} \\ \hline
GPU\_OCL & 502.16             & 25.08        & 78.38   & 15.53                       & 173.01            \\ \hline
CPU\_OCL & 3735.66            & 281.53       & 400.39  & 96.86                       & 990.07            \\ \hline
ORG      & 24925.70           & 6664.20      & 7660.12 & 569.38                      & 17189.30          \\ \hline
\end{tabular*} \\[2pt]
\footnotesize 单位：毫秒
\end{minipage}
\end{table}

\begin{table}[htb]
\centering
\begin{minipage}[t]{0.94\linewidth}
\caption{各Kernel的加速比对比}
\label{tldkernelspeedup}
\begin{tabular*}{\linewidth}{|l|c|c|c|c|c|}
\hline
\backslashbox{\footnotesize 计算设备\kern-0.5cm}{\kern-0.5cm Kernel}  & FFE & FC & NCC     & GONS & GPS \\ \hline
GPU\_OCL & 49.64 (7.44)       & 265.74 (11.23) & 97.73 (5.11) & 36.65 (6.24)                & 99.35 (5.72)      \\ \hline
CPU\_OCL & 6.67               & 23.67          & 19.13        & 5.88                        & 17.36             \\ \hline
ORG      & 1.00               & 1.00           & 1.00         & 1.00                        & 1.00              \\ \hline
\end{tabular*}
\end{minipage}
\end{table}

表\ref{tldkerneltime}给出了5个Kernel在不同设备上的时间开销。
其中GPU\_OCL和CPU\_OCL分别代表GPU和CPU上的各OpenCL Kernel总执行时间。
ORG代表OpenTLD中对应于各Kernel的代码段的总执行时间。
与表\ref{tldkerneltime}对应的，以OpenTLD为基准的加速比如表\ref{tldkernelspeedup}所示，其中括号内的加速比为GPU\_OCL相对于CPU\_OCL的加速比。
可以看出，通过本章基于OpenCL的并行化实现，无论在CPU还是GPU上，各个Kernel均取得了令人满意的性能提升。
性能提升较低的两个Kernel是GetOverlapAndNegativeSample和FernFeatureExtract。
在执行GetOverlapAndNegativeSample的过程中，绝大部分的边界框由于与$currentBB$不相交（\texttt{overlap==0}），
不会进入表\ref{overlapcode}的16$\sim$21行的重叠率计算。
因此并行化版本相比原OpenTLD版本的优势有所降低。
FernFeatureExtract的计算量很小，仅为像素灰度对比和移位，
但访存却较为复杂，需3次不规则的间接访存（图\ref{fernext}，通过边界框索引访问网格数组，通过采样模式和网格数组访问帧图像中两个像素）。
因此并行化实现不能充分地利用计算资源和访存带宽。

此外，还可以看出，Kernel在GPU上的执行时间明显短于在CPU上，加速比基本在6倍左右。
GPU相对于CPU加速比最低的Kernel为NCC，原因在于Kernel的主要部分为树形归约（表\ref{ncccode}第23$\sim$32行），
而GPU体系结构不适于归约操作。归约过程中循环的次数越多，同时参与计算的流处理器越少。
直至最后一次循环时，仅有一个工作项负责最后两个元素的累加。
GPU相对于CPU加速比最高的Kernel为FernClassify，主要原因在于输入的边界框数量较大，而每个边界框就有10个Fern特征向量需要分类，
导致工作项数量庞大，适于用GPU的大量流处理器进行并行处理。
除了CPU和GPU本身的计算能力差别，以及Kernel计算负载自身的特点，导致CPU和GPU上Kernel性能差别的另一主要因素就是实现的优化。
因为GPU体系结构与OpenCL平台模型最为相似，本章的Kernel在实现时主要考虑了GPU平台，而没有针对CPU的体系结构特点。
这就导致了OpenCL的性能移植性问题，下一章将针对该问题进行专门探讨。

使用OpenCL进行并行化，在带来计算效率的显著提高的同时，势必会引入额外的时间开销。
最为显著的额外开销是数据的重组和传输。
例如，在执行Kernel NCC之前，需要将所有边界框对应的图像块，和所有正负样本图像块，分别连续地转存在两个一维数组之中。
由于这两个一维数组在跟踪过程中长度不断变化，还需要为它们重新创建OpenCL存储对象，并传输到计算设备。
此外，额外开销还包括命令队列的维护、Kernel的启动开销等。

为了更加公平地评测本章TLD实现的Kernel性能，这里考虑所有的额外开销，将TLD算法的3个部分的执行时间进行对比。
这3个部分分别是：
\begin{compactitem}
\item Fern随机森林分类：包含了Fern特征提取和分类过程的两个Kernel及前后数据处理、传输；
\item 最邻近分类：包含了NCC计算Kernel、置信度计算和数据重组、传输；
\item 学习过程中的正负样本提取：包含了重叠率计算和正负样本提取的两个Kernel，Kernel循环调用，以及数据传输。
\end{compactitem}
3个部分中，有的部分包含两个Kernel。这样划分的原因是，两个Kernel间有数据共享或者是生产者—消费者关系，难以确定额外开销属于哪个Kernel。
与之前的对比类似，这里指定3个部分中的Kernel全部在GPU或CPU上运行，并统计时间开销。
值得注意的是，当Kernel在CPU上运行时，由于计算设备就是宿主处理器，所以无需真正传输或者拷贝数据，数据传输开销可以忽略。
同样地，OpenTLD中对应于这3个部分的代码段也被提取出来，以统计时间开销，作为对比基准。
3部分在不同计算设备上的执行时间对比如图\ref{tldparttime}所示。
可以看出，考虑所有额外开销后，无论在CPU还是GPU上，各部分仍然有令人满意的加速。
同时，相比单纯的Kernel执行时间，加速比出现下降。
这说明使用OpenCL并行化必然引入的额外开销较多，但是不会抵消并行化带来的巨大性能提升。
对于Fern随机森林分类，使用GPU执行Kernel的性能优于使用CPU。
然而对于最邻近分类，GPU上的性能远低于CPU。原因主要有两点，一是仅考虑NCC Kernel的执行时间，
GPU对于CPU有着最低的加速比（表\ref{tldkernelspeedup}）；
二是GPU上的NCC Kernel需要传输大量数据，即所有边界框对应的图像块和正负样本图像块，此外还需传回所有计算出的NCC，
但CPU不需要这些额外的数据传输。
由于相同的原因，对于正负样本提取，在GPU上执行Kernel的性能略低于在CPU上执行。

\begin{figure}[htb]
  \centering
  \includegraphics[width=14cm]{tldparttime}
  \caption{TLD算法各部分的时间开销对比}
  \label{tldparttime}
\end{figure}

\subsection{整体性能评测与分析}
由于本章实现的是一个完整的应用，因此本节将评测整个应用的性能。
类似上节，本节仍然以\textit{Car}作为输入序列，并统计处理完整个序列所需的时间。
不同的是，通过上一节对TLD算法3个部分的性能评测，已经得出了各部分所适用的计算设备；
并且作为完整应用，可以如\ref{detecttrackoverlapsec}节所述，将光流跟踪和Fern随机森林分类进行重叠执行。
因此，这里将评测4个版本的整体性能：
\begin{compactitem}
\item 指定本章实现的所有Kernel在CPU上执行，光流跟踪在GPU上与Fern随机森林分类重叠执行（记为CPU版本）；
\item 指定本章实现的所有Kernel在GPU上执行，光流跟踪在CPU上与Fern随机森林分类重叠执行（记为GPU版本）；
\item 指定Fern随机森林分类的两个Kernel在GPU上执行，最邻近分类和正负样本提取的3个Kernel在CPU上执行，光流跟踪在CPU上与Fern随机森林分类重叠执行（记为CPU/GPU版本）；
\item 原始OpenTLD版本，作为对比基准（记为ORG版本）。
\end{compactitem}
不同的实现版本在整个序列中完成跟踪所需的时间如图\ref{tldwholetime}所示。

\begin{figure}[htb]
  \centering
  \includegraphics[width=10.5cm]{tldwholetime}
  \caption{整个应用的时间开销对比}
  \label{tldwholetime}
\end{figure}

从图\ref{tldwholetime}中可以看出，所有Kernel均在CPU上执行时的整体性能略高于均在GPU上执行时。
这与上一节的实验结果一致，即GPU在Fern随机森林分类上的优势，被最邻近分类和正负样本提取所抵消。
CPU/GPU版本中，各个Kernel运行在适合的设备上，取得了最佳的整体性能，因此它将作为本章最终的TLD算法高性能实现。
相比OpenTLD，其加速比达到了3.92倍，跟踪速度达到了52.9 FPS，完全满足实时在线跟踪的需求。

\section{小结}
面对跟踪器日益复杂的结构和不断增加的计算负载，高性能的跟踪算法实现变得十分必要。
因此，本章在异构计算平台上，基于可移植的并行编程模型OpenCL，对TLD跟踪算法进行了高性能的实现。
高性能实现中，本章并行化了TLD算法的计算密集部分和瓶颈部分，包括Fern随机森林的特征提取和分类过程，
最邻近分类的NCC计算过程，以及学习过程中的重叠率计算和正负样本提取。
此外，还将Fern随机森林的处理和LK光流跟踪在不同计算设备上进行了重叠执行。
通过实验分析，本章发现OpenCL并行化所引入的额外开销不可忽视，且存在性能移植性问题，
因此高性能实现中，各个Kernel程序将运行在各自适合的计算设备上。
最终的高性能实现取得了令人满意的整体加速比，完全满足实时处理的需求。
但不可否认，本章的高性能实现还远没有达到最佳性能。
未来进一步的工作包括：1. 重构代码：通过调整中间数据的存储方式，减少数据重组的时间开销；
2. 计算和传输重叠：通过在进行计算的同时传输Kernel所需的数据，隐藏数据传输的时间开销；
3. 更精细的并行优化：通过针对不同计算设备的体系结构特点，编写更为特定、高效的Kernel程序。